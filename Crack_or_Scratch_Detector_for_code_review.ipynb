{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Damage detection MLP that monitors folder Inspect and runs automatically\n",
    "I am using Python because I am most comfortable writing ML code in it.  I want to learn Cython so that I can take advantage of C's speed advantage where it is necessary.  \n",
    "\n",
    "So this problem is classification into 50 categories, ie. 2 types of defect * (5 * 5 grid) = 50.  The sample size of 150 is quite small so I used elastic transformation algorithm in the other ipynb notebook called \"ElasticTransform.ipynb\".  Elastic transformation is done on medical imagery which is also overlayed on grids so is appropriate here.  Applying three different transformations on the entire data set gave me an additional 450 images for a total of 600.  \n",
    "\n",
    "I should have tried transfer learning first but I tried MLP (2.5% accuracy), then my own CNN (5% accuracy) and finally Transfer Learning (30% accuracy).  The image augmentation explained above boosted VGG16 transfer learning (Model 2 not Model 1) to 95% on the first try.  I was surprised because my training loss was higher than validation loss.  I learned a valuable lesson on this assignment and that is \"never reinvent the wheel.\"\n",
    "\n",
    "Click on the link to skip to transfer learning.  There is no need to run any cells before transfer learning.\n",
    "[Link to Transfer Learning](#the_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and preprocess images \n",
    "First read them in using cv2 methods and then rescale RGB to range within [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "unsorted\n",
      "\n",
      "\n",
      " ['DataSet/Image/1.png', 'DataSet/Image/10.png', 'DataSet/Image/100.png', 'DataSet/Image/101.png', 'DataSet/Image/102.png', 'DataSet/Image/103.png', 'DataSet/Image/104.png', 'DataSet/Image/105.png', 'DataSet/Image/106.png', 'DataSet/Image/107.png', 'DataSet/Image/108.png', 'DataSet/Image/109.png', 'DataSet/Image/11.png', 'DataSet/Image/110.png', 'DataSet/Image/111.png', 'DataSet/Image/112.png', 'DataSet/Image/113.png', 'DataSet/Image/114.png', 'DataSet/Image/115.png', 'DataSet/Image/116.png', 'DataSet/Image/118.png', 'DataSet/Image/119.png', 'DataSet/Image/12.png', 'DataSet/Image/120.png', 'DataSet/Image/121.png', 'DataSet/Image/122.png', 'DataSet/Image/123.png', 'DataSet/Image/124.png', 'DataSet/Image/125.png', 'DataSet/Image/126.png', 'DataSet/Image/127.png', 'DataSet/Image/128.png', 'DataSet/Image/129.png', 'DataSet/Image/13.png', 'DataSet/Image/130.png', 'DataSet/Image/131.png', 'DataSet/Image/132.png', 'DataSet/Image/133.png', 'DataSet/Image/134.png', 'DataSet/Image/135.png', 'DataSet/Image/137.png', 'DataSet/Image/138.png', 'DataSet/Image/139.png', 'DataSet/Image/14.png', 'DataSet/Image/140.png', 'DataSet/Image/141.png', 'DataSet/Image/142.png', 'DataSet/Image/143.png', 'DataSet/Image/144.png', 'DataSet/Image/145.png', 'DataSet/Image/146.png', 'DataSet/Image/147.png', 'DataSet/Image/148.png', 'DataSet/Image/149.png', 'DataSet/Image/15.png', 'DataSet/Image/150.png', 'DataSet/Image/16.png', 'DataSet/Image/17.png', 'DataSet/Image/18.png', 'DataSet/Image/19.png', 'DataSet/Image/20.png', 'DataSet/Image/21.png', 'DataSet/Image/22.png', 'DataSet/Image/23.png', 'DataSet/Image/24.png', 'DataSet/Image/25.png', 'DataSet/Image/26.png', 'DataSet/Image/27.png', 'DataSet/Image/28.png', 'DataSet/Image/29.png', 'DataSet/Image/3.png', 'DataSet/Image/30.png', 'DataSet/Image/31.png', 'DataSet/Image/32.png', 'DataSet/Image/33.png', 'DataSet/Image/34.png', 'DataSet/Image/35.png', 'DataSet/Image/36.png', 'DataSet/Image/37.png', 'DataSet/Image/38.png', 'DataSet/Image/4.png', 'DataSet/Image/40.png', 'DataSet/Image/41.png', 'DataSet/Image/42.png', 'DataSet/Image/43.png', 'DataSet/Image/44.png', 'DataSet/Image/45.png', 'DataSet/Image/46.png', 'DataSet/Image/47.png', 'DataSet/Image/48.png', 'DataSet/Image/49.png', 'DataSet/Image/5.png', 'DataSet/Image/50.png', 'DataSet/Image/51.png', 'DataSet/Image/52.png', 'DataSet/Image/53.png', 'DataSet/Image/54.png', 'DataSet/Image/55.png', 'DataSet/Image/56.png', 'DataSet/Image/57.png', 'DataSet/Image/117.png', 'DataSet/Image/136.png', 'DataSet/Image/2.png', 'DataSet/Image/39.png', 'DataSet/Image/58.png', 'DataSet/Image/77.png', 'DataSet/Image/59.png', 'DataSet/Image/6.png', 'DataSet/Image/60.png', 'DataSet/Image/61.png', 'DataSet/Image/62.png', 'DataSet/Image/63.png', 'DataSet/Image/64.png', 'DataSet/Image/65.png', 'DataSet/Image/66.png', 'DataSet/Image/67.png', 'DataSet/Image/68.png', 'DataSet/Image/69.png', 'DataSet/Image/7.png', 'DataSet/Image/70.png', 'DataSet/Image/71.png', 'DataSet/Image/72.png', 'DataSet/Image/73.png', 'DataSet/Image/74.png', 'DataSet/Image/75.png', 'DataSet/Image/76.png', 'DataSet/Image/78.png', 'DataSet/Image/79.png', 'DataSet/Image/8.png', 'DataSet/Image/80.png', 'DataSet/Image/81.png', 'DataSet/Image/82.png', 'DataSet/Image/83.png', 'DataSet/Image/84.png', 'DataSet/Image/85.png', 'DataSet/Image/86.png', 'DataSet/Image/87.png', 'DataSet/Image/88.png', 'DataSet/Image/89.png', 'DataSet/Image/9.png', 'DataSet/Image/90.png', 'DataSet/Image/91.png', 'DataSet/Image/92.png', 'DataSet/Image/93.png', 'DataSet/Image/94.png', 'DataSet/Image/95.png', 'DataSet/Image/96.png', 'DataSet/Image/97.png', 'DataSet/Image/98.png', 'DataSet/Image/99.png']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sorted\n",
      "\n",
      "\n",
      "\n",
      " ['DataSet/Image/1.png', 'DataSet/Image/2.png', 'DataSet/Image/3.png', 'DataSet/Image/4.png', 'DataSet/Image/5.png', 'DataSet/Image/6.png', 'DataSet/Image/7.png', 'DataSet/Image/8.png', 'DataSet/Image/9.png', 'DataSet/Image/10.png', 'DataSet/Image/11.png', 'DataSet/Image/12.png', 'DataSet/Image/13.png', 'DataSet/Image/14.png', 'DataSet/Image/15.png', 'DataSet/Image/16.png', 'DataSet/Image/17.png', 'DataSet/Image/18.png', 'DataSet/Image/19.png', 'DataSet/Image/20.png', 'DataSet/Image/21.png', 'DataSet/Image/22.png', 'DataSet/Image/23.png', 'DataSet/Image/24.png', 'DataSet/Image/25.png', 'DataSet/Image/26.png', 'DataSet/Image/27.png', 'DataSet/Image/28.png', 'DataSet/Image/29.png', 'DataSet/Image/30.png', 'DataSet/Image/31.png', 'DataSet/Image/32.png', 'DataSet/Image/33.png', 'DataSet/Image/34.png', 'DataSet/Image/35.png', 'DataSet/Image/36.png', 'DataSet/Image/37.png', 'DataSet/Image/38.png', 'DataSet/Image/39.png', 'DataSet/Image/40.png', 'DataSet/Image/41.png', 'DataSet/Image/42.png', 'DataSet/Image/43.png', 'DataSet/Image/44.png', 'DataSet/Image/45.png', 'DataSet/Image/46.png', 'DataSet/Image/47.png', 'DataSet/Image/48.png', 'DataSet/Image/49.png', 'DataSet/Image/50.png', 'DataSet/Image/51.png', 'DataSet/Image/52.png', 'DataSet/Image/53.png', 'DataSet/Image/54.png', 'DataSet/Image/55.png', 'DataSet/Image/56.png', 'DataSet/Image/57.png', 'DataSet/Image/58.png', 'DataSet/Image/59.png', 'DataSet/Image/60.png', 'DataSet/Image/61.png', 'DataSet/Image/62.png', 'DataSet/Image/63.png', 'DataSet/Image/64.png', 'DataSet/Image/65.png', 'DataSet/Image/66.png', 'DataSet/Image/67.png', 'DataSet/Image/68.png', 'DataSet/Image/69.png', 'DataSet/Image/70.png', 'DataSet/Image/71.png', 'DataSet/Image/72.png', 'DataSet/Image/73.png', 'DataSet/Image/74.png', 'DataSet/Image/75.png', 'DataSet/Image/76.png', 'DataSet/Image/77.png', 'DataSet/Image/78.png', 'DataSet/Image/79.png', 'DataSet/Image/80.png', 'DataSet/Image/81.png', 'DataSet/Image/82.png', 'DataSet/Image/83.png', 'DataSet/Image/84.png', 'DataSet/Image/85.png', 'DataSet/Image/86.png', 'DataSet/Image/87.png', 'DataSet/Image/88.png', 'DataSet/Image/89.png', 'DataSet/Image/90.png', 'DataSet/Image/91.png', 'DataSet/Image/92.png', 'DataSet/Image/93.png', 'DataSet/Image/94.png', 'DataSet/Image/95.png', 'DataSet/Image/96.png', 'DataSet/Image/97.png', 'DataSet/Image/98.png', 'DataSet/Image/99.png', 'DataSet/Image/100.png', 'DataSet/Image/101.png', 'DataSet/Image/102.png', 'DataSet/Image/103.png', 'DataSet/Image/104.png', 'DataSet/Image/105.png', 'DataSet/Image/106.png', 'DataSet/Image/107.png', 'DataSet/Image/108.png', 'DataSet/Image/109.png', 'DataSet/Image/110.png', 'DataSet/Image/111.png', 'DataSet/Image/112.png', 'DataSet/Image/113.png', 'DataSet/Image/114.png', 'DataSet/Image/115.png', 'DataSet/Image/116.png', 'DataSet/Image/117.png', 'DataSet/Image/118.png', 'DataSet/Image/119.png', 'DataSet/Image/120.png', 'DataSet/Image/121.png', 'DataSet/Image/122.png', 'DataSet/Image/123.png', 'DataSet/Image/124.png', 'DataSet/Image/125.png', 'DataSet/Image/126.png', 'DataSet/Image/127.png', 'DataSet/Image/128.png', 'DataSet/Image/129.png', 'DataSet/Image/130.png', 'DataSet/Image/131.png', 'DataSet/Image/132.png', 'DataSet/Image/133.png', 'DataSet/Image/134.png', 'DataSet/Image/135.png', 'DataSet/Image/136.png', 'DataSet/Image/137.png', 'DataSet/Image/138.png', 'DataSet/Image/139.png', 'DataSet/Image/140.png', 'DataSet/Image/141.png', 'DataSet/Image/142.png', 'DataSet/Image/143.png', 'DataSet/Image/144.png', 'DataSet/Image/145.png', 'DataSet/Image/146.png', 'DataSet/Image/147.png', 'DataSet/Image/148.png', 'DataSet/Image/149.png', 'DataSet/Image/150.png']\n",
      "len images  150\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#read in 100 by 100 pixel images \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from natsort import natsorted\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "filenames = [img for img in glob.glob(\"DataSet/Image/*.png\")]\n",
    "\n",
    "filenames = natsorted(filenames)\n",
    "\n",
    "images = [cv2.imread(img) for img in filenames]\n",
    "\n",
    "#check that we have 150 images\n",
    "print(\"len images \", len(images))\n",
    "\n",
    "#convert from BGR to RGB \n",
    "for img in images:\n",
    "    img[np.where((img == [0, 0, 255]).all(axis=2))] = [255, 0, 0]\n",
    "\n",
    "#plot first 3 images in dataset\n",
    "for i in range(3):\n",
    "    plt.imshow(images[i])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAC5dJREFUeJzt3X+onYV9x/H3Z7lNnSmrUS+SJrpkKC1S6FIuTnGMoe1mXan+IcVSRhhC/phb7Q9odfuj7L8JpdY/RiHoStiktUtlCVJautT+sX8yr1VWTbRmajUh6hWMLf1nDf3uj/M4bkPqPbn3nPuD7/sFl3Of5zwnz5eHvM/znCdHTFUhqZffWesBJK0+w5caMnypIcOXGjJ8qSHDlxoyfKmhFYWf5KYkzyU5nuTuSQ0labqy3C/wJNkE/BT4KHACeBz4VFUdndx4kqZhZgWvvQY4XlUvACT5FnAL8FvDv/TSS2vnzp0r2KWkd/LSSy/xxhtvZKntVhL+duCVRcsngD86e6Mke4G9AFdccQXz8/Mr2KWkdzI3NzfWdlO/uVdV+6pqrqrmZmdnp707SWNYSfgngcsXLe8Y1kla51YS/uPAVUl2JdkM3A4cmsxYkqZp2Z/xq+pMkr8Bvg9sAv65qp6Z2GSSpmYlN/eoqu8C353QLJJWid/ckxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKmhFf0vtNTcL94aPf7rQ6PHZ4+NHl94efR46ODoMas7lpbmGV9qyDO+lm/+8dHjX9/5m+u37xw9eqZftzzjSw15xtfynT597vW7d6/uHDpvnvGlhjzja/n+7GOjx6q1nUPnzTO+1NCS4Se5PMljSY4meSbJXcP6i5P8IMnzw+PW6Y+rdWXLltGPNpxxzvhngC9U1dXAtcCdSa4G7gYOV9VVwOFhWdIGsGT4VXWqqn48/P4L4BiwHbgF2D9sth+4dVpDSpqs8/qMn2QnsBs4AlxWVaeGp14FLpvoZJKmZuzwk7wH+A7w2ar6+eLnqqqAc97aTbI3yXyS+YWFhRUNK2kyxgo/ybsYRf9QVT0yrH4tybbh+W3A6+d6bVXtq6q5qpqbnZ2dxMySVmicu/oBHgSOVdVXFz11CNgz/L4HODj58SRNwzhf4Lke+EvgJ0meGtb9HfCPwLeT3AH8DPjkdEaUNGlLhl9V/8lv/++sbpzsOJJWg9/ckxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGjJ8qSHDlxoyfKkhw5caMnypIcOXGho7/CSbkjyZ5NFheVeSI0mOJ3k4yebpjSlpks7njH8XcGzR8r3AfVV1JfAmcMckB5M0PWOFn2QH8BfAA8NygBuAA8Mm+4FbpzGgpMkb94z/NeCLwK+H5UuA01V1Zlg+AWw/1wuT7E0yn2R+YWFhRcNKmowlw0/yceD1qnpiOTuoqn1VNVdVc7Ozs8v5IyRN2MwY21wPfCLJzcAFwO8B9wMXJZkZzvo7gJPTG1PSJC15xq+qe6pqR1XtBG4HflhVnwYeA24bNtsDHJzalJImaiX/jv8l4PNJjjP6zP/gZEaSNG3jXOr/v6r6EfCj4fcXgGsmP5KkafObe1JDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNWT4UkOGLzVk+FJDhi81ZPhSQ4YvNTRW+EkuSnIgybNJjiW5LsnFSX6Q5Pnhceu0h5U0GeOe8e8HvldVHwA+BBwD7gYOV9VVwOFhWdIGsGT4Sd4L/AnwIEBV/W9VnQZuAfYPm+0Hbp3WkJIma5wz/i5gAfhGkieTPJBkC3BZVZ0atnkVuGxaQ0qarHHCnwE+DHy9qnYDv+Ssy/qqKqDO9eIke5PMJ5lfWFhY6bySJmCc8E8AJ6rqyLB8gNEbwWtJtgEMj6+f68VVta+q5qpqbnZ2dhIzS1qhJcOvqleBV5K8f1h1I3AUOATsGdbtAQ5OZUJJEzcz5nZ/CzyUZDPwAvBXjN40vp3kDuBnwCenM6KkSRsr/Kp6Cpg7x1M3TnYcSavBb+5JDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNjRV+ks8leSbJ00m+meSCJLuSHElyPMnDSTZPe1hJk7Fk+Em2A58B5qrqg8Am4HbgXuC+qroSeBO4Y5qDSpqccS/1Z4DfTTIDXAicAm4ADgzP7wdunfx4kqZhyfCr6iTwFeBlRsG/BTwBnK6qM8NmJ4Dt53p9kr1J5pPMLywsTGZqSSsyzqX+VuAWYBfwPmALcNO4O6iqfVU1V1Vzs7Ozyx5U0uSMc6n/EeDFqlqoql8BjwDXAxcNl/4AO4CTU5pR0oSNE/7LwLVJLkwS4EbgKPAYcNuwzR7g4HRGlDRp43zGP8LoJt6PgZ8Mr9kHfAn4fJLjwCXAg1OcU9IEzSy9CVTVl4Evn7X6BeCaiU8kaer85p7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UkOFLDRm+1JDhSw0ZvtSQ4UsNGb7UUKpq9XaWLAC/BN5YtZ2uzKVsnFlhY827kWaFjTPv71fV7FIbrWr4AEnmq2puVXe6TBtpVthY826kWWHjzbsUL/Wlhgxfamgtwt+3Bvtcro00K2yseTfSrLDx5n1Hq/4ZX9La81JfamjVwk9yU5LnkhxPcvdq7XdcSS5P8liSo0meSXLXsP7iJD9I8vzwuHWtZ31bkk1Jnkzy6LC8K8mR4Rg/nGTzWs/4tiQXJTmQ5Nkkx5Jct16PbZLPDX8Hnk7yzSQXrOdjuxyrEn6STcA/AR8DrgY+leTq1dj3eTgDfKGqrgauBe4cZrwbOFxVVwGHh+X14i7g2KLle4H7qupK4E3gjjWZ6tzuB75XVR8APsRo7nV3bJNsBz4DzFXVB4FNwO2s72N7/qpq6j/AdcD3Fy3fA9yzGvtewcwHgY8CzwHbhnXbgOfWerZhlh2MYrkBeBQIoy+YzJzrmK/xrO8FXmS4p7Ro/bo7tsB24BXgYmBmOLZ/vl6P7XJ/VutS/+2D+bYTw7p1KclOYDdwBLisqk4NT70KXLZGY53ta8AXgV8Py5cAp6vqzLC8no7xLmAB+Mbw0eSBJFtYh8e2qk4CXwFeBk4BbwFPsH6P7bJ4c+8sSd4DfAf4bFX9fPFzNXq7X/N/BknyceD1qnpirWcZ0wzwYeDrVbWb0de2f+Oyfh0d263ALYzerN4HbAFuWtOhpmC1wj8JXL5oecewbl1J8i5G0T9UVY8Mq19Lsm14fhvw+lrNt8j1wCeSvAR8i9Hl/v3ARUlmhm3W0zE+AZyoqiPD8gFGbwTr8dh+BHixqhaq6lfAI4yO93o9tsuyWuE/Dlw13BndzOhmyaFV2vdYkgR4EDhWVV9d9NQhYM/w+x5Gn/3XVFXdU1U7qmono2P5w6r6NPAYcNuw2bqYFaCqXgVeSfL+YdWNwFHW4bFldIl/bZILh78Tb8+6Lo/tsq3iTZObgZ8C/wP8/Vrf3DjHfH/M6FLzv4Gnhp+bGX12Pgw8D/wHcPFaz3rW3H8KPDr8/gfAfwHHgX8D3r3W8y2a8w+B+eH4/juwdb0eW+AfgGeBp4F/Ad69no/tcn785p7UkDf3pIYMX2rI8KWGDF9qyPClhgxfasjwpYYMX2ro/wCL1bSy6TdMGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Load distorted.npy which are the elastic transformations and combine data sets to make one big data set of\n",
    "600 images\"\"\"\n",
    "import numpy as np\n",
    "distorted1 = np.load(\"DataSet/AugImages/distorted1/distorted1.npy\")\n",
    "distorted2 = np.load(\"DataSet/AugImages/distorted2/distorted2.npy\")\n",
    "distorted3 = np.load(\"DataSet/AugImages/distorted3/distorted3.npy\")\n",
    "\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "combined_data = np.concatenate((images, distorted1, distorted2, distorted3), axis=0)\n",
    "\n",
    "#check for 600\n",
    "print(len(combined_data))\n",
    "\n",
    "#plot and check first and last 3 images\n",
    "for i in range(3):\n",
    "    plt.imshow(combined_data[i])\n",
    "    plt.show()\n",
    "for i in range(3):    \n",
    "    plt.imshow(combined_data[-i-1])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#divide into training and test sets\\nx_train = images[:100]\\nx_valid = images[100:130]\\nx_test = images[130:]\\nx_train = np.array(x_train)\\nx_valid = np.array(x_valid)\\nx_test = np.array(x_test)\\n\\n#rescale\\nx_train = x_train/255.0\\nx_valid = x_valid/255.0\\nx_test = x_test/255.0\\n\\nprint(\"train\\n\\n\", x_train[1]) #matrix of 100 * 100 * 3\\nprint(\"test\\n\\n\", x_test[1])\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "SKIP THIS CELL \n",
    "\n",
    "#divide into training and test sets\n",
    "x_train = images[:100]\n",
    "x_valid = images[100:130]\n",
    "x_test = images[130:]\n",
    "x_train = np.array(x_train)\n",
    "x_valid = np.array(x_valid)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "#rescale\n",
    "x_train = x_train/255.0\n",
    "x_valid = x_valid/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "print(\"train\\n\\n\", x_train[1]) #matrix of 100 * 100 * 3\n",
    "print(\"test\\n\\n\", x_test[1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create labels for data in csv file for 1.png to 150.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FileName', ' DefectLocation', ' Cause']\n",
      "    FileName  DefectLocation     Cause\n",
      "0      1.png              B4   Scratch\n",
      "1      2.png              B4     Crack\n",
      "2      3.png              D3     Crack\n",
      "3      4.png              D5     Crack\n",
      "4      5.png              E4   Scratch\n",
      "5      6.png              B2     Crack\n",
      "6      7.png              c5     Crack\n",
      "7      8.png              E2   Scratch\n",
      "8      9.png              D3   Scratch\n",
      "9     10.png              B2   Scratch\n",
      "10    11.png              E4     Crack\n",
      "11    12.png              D1   Scratch\n",
      "12    13.png              c2   Scratch\n",
      "13    14.png              D4     Crack\n",
      "14    15.png              c2   Scratch\n",
      "15    16.png              B3     Crack\n",
      "16    17.png              A1     Crack\n",
      "17    18.png              E5   Scratch\n",
      "18    19.png              B3     Crack\n",
      "19    20.png              A2   Scratch\n",
      "20    21.png              c2   Scratch\n",
      "21    22.png              E4   Scratch\n",
      "22    23.png              D1   Scratch\n",
      "23    24.png              D3     Crack\n",
      "24    25.png              A4   Scratch\n",
      "25    26.png              D2   Scratch\n",
      "26    27.png              c3     Crack\n",
      "27    28.png              c1   Scratch\n",
      "28    29.png              c5   Scratch\n",
      "29    30.png              E3     Crack\n",
      "..       ...             ...       ...\n",
      "120  121.png              B1     Crack\n",
      "121  122.png              A3   Scratch\n",
      "122  123.png              A4     Crack\n",
      "123  124.png              c1   Scratch\n",
      "124  125.png              D4     Crack\n",
      "125  126.png              E1   Scratch\n",
      "126  127.png              D1   Scratch\n",
      "127  128.png              c3     Crack\n",
      "128  129.png              D2   Scratch\n",
      "129  130.png              B5   Scratch\n",
      "130  131.png              c5   Scratch\n",
      "131  132.png              c1     Crack\n",
      "132  133.png              D3   Scratch\n",
      "133  134.png              D3     Crack\n",
      "134  135.png              B5     Crack\n",
      "135  136.png              D4   Scratch\n",
      "136  137.png              A5     Crack\n",
      "137  138.png              B1   Scratch\n",
      "138  139.png              B4     Crack\n",
      "139  140.png              D3     Crack\n",
      "140  141.png              c5   Scratch\n",
      "141  142.png              A1     Crack\n",
      "142  143.png              B2   Scratch\n",
      "143  144.png              E2     Crack\n",
      "144  145.png              c1     Crack\n",
      "145  146.png              D1     Crack\n",
      "146  147.png              B5     Crack\n",
      "147  148.png              c1     Crack\n",
      "148  149.png              D1   Scratch\n",
      "149  150.png              A1     Crack\n",
      "\n",
      "[150 rows x 3 columns]\n",
      "    FileName\n",
      "0      1.png\n",
      "1      2.png\n",
      "2      3.png\n",
      "3      4.png\n",
      "4      5.png\n",
      "5      6.png\n",
      "6      7.png\n",
      "7      8.png\n",
      "8      9.png\n",
      "9     10.png\n",
      "10    11.png\n",
      "11    12.png\n",
      "12    13.png\n",
      "13    14.png\n",
      "14    15.png\n",
      "15    16.png\n",
      "16    17.png\n",
      "17    18.png\n",
      "18    19.png\n",
      "19    20.png\n",
      "20    21.png\n",
      "21    22.png\n",
      "22    23.png\n",
      "23    24.png\n",
      "24    25.png\n",
      "25    26.png\n",
      "26    27.png\n",
      "27    28.png\n",
      "28    29.png\n",
      "29    30.png\n",
      "..       ...\n",
      "120  121.png\n",
      "121  122.png\n",
      "122  123.png\n",
      "123  124.png\n",
      "124  125.png\n",
      "125  126.png\n",
      "126  127.png\n",
      "127  128.png\n",
      "128  129.png\n",
      "129  130.png\n",
      "130  131.png\n",
      "131  132.png\n",
      "132  133.png\n",
      "133  134.png\n",
      "134  135.png\n",
      "135  136.png\n",
      "136  137.png\n",
      "137  138.png\n",
      "138  139.png\n",
      "139  140.png\n",
      "140  141.png\n",
      "141  142.png\n",
      "142  143.png\n",
      "143  144.png\n",
      "144  145.png\n",
      "145  146.png\n",
      "146  147.png\n",
      "147  148.png\n",
      "148  149.png\n",
      "149  150.png\n",
      "\n",
      "[150 rows x 1 columns]\n",
      "[' B4', ' B4', ' D3', ' D5', ' E4', ' B2', ' c5', ' E2', ' D3', ' B2', ' E4', ' D1', ' c2', ' D4', ' c2', ' B3', ' A1', ' E5', ' B3', ' A2', ' c2', ' E4', ' D1', ' D3', ' A4', ' D2', ' c3', ' c1', ' c5', ' E3', ' E3', ' c2', ' B4', ' c4', ' A3', ' A5', ' B4', ' c3', ' A1', ' A2', ' c4', ' E4', ' B4', ' E3', ' B1', ' c2', ' D3', ' D3', ' D2', ' E2', ' A1', ' D1', ' E1', ' B5', ' c2', ' B2', ' A3', ' c2', ' D4', ' D2', ' B2', ' c5', ' B3', ' E4', ' A2', ' E1', ' D2', ' B4', ' B4', ' c5', ' D1', ' B5', ' E1', ' E5', ' c2', ' c2', ' B5', ' E1', ' B5', ' c1', ' c4', ' c1', ' B4', ' E5', ' D5', ' c4', ' A5', ' D2', ' E4', ' A5', ' A3', ' B2', ' A1', ' B2', ' c2', ' c1', ' c5', ' A2', ' E5', ' c4', ' c1', ' B5', ' A3', ' A2', ' c5', ' D1', ' A3', ' E3', ' D1', ' E3', ' D3', ' D4', ' D1', ' c2', ' D2', ' D3', ' c1', ' c2', ' D4', ' D4', ' B1', ' A3', ' A4', ' c1', ' D4', ' E1', ' D1', ' c3', ' D2', ' B5', ' c5', ' c1', ' D3', ' D3', ' B5', ' D4', ' A5', ' B1', ' B4', ' D3', ' c5', ' A1', ' B2', ' E2', ' c1', ' D1', ' B5', ' c1', ' D1', ' A1']\n",
      "[' Scratch', ' Crack', ' Crack', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Crack', ' Crack', ' Crack', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Crack', ' Crack', ' Crack', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Scratch', ' Crack', ' Crack', ' Crack', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Crack', ' Crack', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Crack', ' Crack', ' Crack', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Crack', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Scratch', ' Scratch', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Crack', ' Scratch', ' Crack', ' Crack', ' Scratch', ' Crack', ' Scratch', ' Crack', ' Crack', ' Crack', ' Crack', ' Crack', ' Scratch', ' Crack']\n",
      "\n",
      "\n",
      "\n",
      "data_labels\n",
      " [(' B4', ' Scratch'), (' B4', ' Crack'), (' D3', ' Crack'), (' D5', ' Crack'), (' E4', ' Scratch'), (' B2', ' Crack'), (' c5', ' Crack'), (' E2', ' Scratch'), (' D3', ' Scratch'), (' B2', ' Scratch'), (' E4', ' Crack'), (' D1', ' Scratch'), (' c2', ' Scratch'), (' D4', ' Crack'), (' c2', ' Scratch'), (' B3', ' Crack'), (' A1', ' Crack'), (' E5', ' Scratch'), (' B3', ' Crack'), (' A2', ' Scratch'), (' c2', ' Scratch'), (' E4', ' Scratch'), (' D1', ' Scratch'), (' D3', ' Crack'), (' A4', ' Scratch'), (' D2', ' Scratch'), (' c3', ' Crack'), (' c1', ' Scratch'), (' c5', ' Scratch'), (' E3', ' Crack'), (' E3', ' Crack'), (' c2', ' Crack'), (' B4', ' Scratch'), (' c4', ' Crack'), (' A3', ' Scratch'), (' A5', ' Scratch'), (' B4', ' Scratch'), (' c3', ' Scratch'), (' A1', ' Crack'), (' A2', ' Scratch'), (' c4', ' Crack'), (' E4', ' Crack'), (' B4', ' Scratch'), (' E3', ' Crack'), (' B1', ' Crack'), (' c2', ' Crack'), (' D3', ' Crack'), (' D3', ' Scratch'), (' D2', ' Crack'), (' E2', ' Crack'), (' A1', ' Scratch'), (' D1', ' Scratch'), (' E1', ' Crack'), (' B5', ' Crack'), (' c2', ' Scratch'), (' B2', ' Scratch'), (' A3', ' Crack'), (' c2', ' Crack'), (' D4', ' Crack'), (' D2', ' Scratch'), (' B2', ' Scratch'), (' c5', ' Scratch'), (' B3', ' Scratch'), (' E4', ' Crack'), (' A2', ' Scratch'), (' E1', ' Crack'), (' D2', ' Scratch'), (' B4', ' Scratch'), (' B4', ' Crack'), (' c5', ' Crack'), (' D1', ' Scratch'), (' B5', ' Crack'), (' E1', ' Crack'), (' E5', ' Scratch'), (' c2', ' Crack'), (' c2', ' Crack'), (' B5', ' Scratch'), (' E1', ' Crack'), (' B5', ' Crack'), (' c1', ' Crack'), (' c4', ' Scratch'), (' c1', ' Crack'), (' B4', ' Crack'), (' E5', ' Scratch'), (' D5', ' Scratch'), (' c4', ' Scratch'), (' A5', ' Crack'), (' D2', ' Scratch'), (' E4', ' Scratch'), (' A5', ' Scratch'), (' A3', ' Scratch'), (' B2', ' Scratch'), (' A1', ' Scratch'), (' B2', ' Scratch'), (' c2', ' Crack'), (' c1', ' Crack'), (' c5', ' Scratch'), (' A2', ' Scratch'), (' E5', ' Scratch'), (' c4', ' Scratch'), (' c1', ' Scratch'), (' B5', ' Crack'), (' A3', ' Scratch'), (' A2', ' Crack'), (' c5', ' Crack'), (' D1', ' Crack'), (' A3', ' Scratch'), (' E3', ' Crack'), (' D1', ' Scratch'), (' E3', ' Scratch'), (' D3', ' Scratch'), (' D4', ' Scratch'), (' D1', ' Scratch'), (' c2', ' Scratch'), (' D2', ' Crack'), (' D3', ' Scratch'), (' c1', ' Crack'), (' c2', ' Crack'), (' D4', ' Scratch'), (' D4', ' Crack'), (' B1', ' Crack'), (' A3', ' Scratch'), (' A4', ' Crack'), (' c1', ' Scratch'), (' D4', ' Crack'), (' E1', ' Scratch'), (' D1', ' Scratch'), (' c3', ' Crack'), (' D2', ' Scratch'), (' B5', ' Scratch'), (' c5', ' Scratch'), (' c1', ' Crack'), (' D3', ' Scratch'), (' D3', ' Crack'), (' B5', ' Crack'), (' D4', ' Scratch'), (' A5', ' Crack'), (' B1', ' Scratch'), (' B4', ' Crack'), (' D3', ' Crack'), (' c5', ' Scratch'), (' A1', ' Crack'), (' B2', ' Scratch'), (' E2', ' Crack'), (' c1', ' Crack'), (' D1', ' Crack'), (' B5', ' Crack'), (' c1', ' Crack'), (' D1', ' Scratch'), (' A1', ' Crack')]\n",
      "len data_labels 150\n"
     ]
    }
   ],
   "source": [
    "#create Pandas dataframe from csv to make labels for the images\n",
    "import pandas as pd\n",
    "\n",
    "labels_df = pd.read_csv('DataSet/data.csv')\n",
    "\n",
    "#clean whitespaces\n",
    "labels_df['FileName'].str.strip()\n",
    "labels_df[' DefectLocation'].str.strip()\n",
    "labels_df[' Cause'].str.strip()\n",
    "\n",
    "#slice the FileName column\n",
    "df1 = labels_df[['FileName']]\n",
    "\n",
    "#slice the location and cause cols to create target labels\n",
    "df2 = labels_df[[' DefectLocation', ' Cause']]\n",
    "location = df2[' DefectLocation'].tolist()\n",
    "cause = df2[' Cause'].tolist()\n",
    "\n",
    "#make the labels here as a list of tuples\n",
    "data_labels = []\n",
    "for i in range(len(location)):\n",
    "    tupleObj = (location[i], cause[i])\n",
    "    data_labels.append(tupleObj)\n",
    "print(\"\\n\\n\\ndata_labels\\n\", data_labels)\n",
    "print(\"len data_labels\", len(data_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encode the labels \n",
    "Form a vector of 50 elements, 0 to 24 are A1 to E5 for cracks and 25 to 49 are A1 to E5 for scratches\n",
    "First form tuples and then let the tuples be one hot encoded.\n",
    "Let cracks = 0, scratch = 1 and form tuples, ie. (1,1) would be (A1, scratch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' A1', ' Crack'), (' A2', ' Crack'), (' A3', ' Crack'), (' A4', ' Crack'), (' A5', ' Crack'), (' B1', ' Crack'), (' B2', ' Crack'), (' B3', ' Crack'), (' B4', ' Crack'), (' B5', ' Crack'), (' c1', ' Crack'), (' c2', ' Crack'), (' c3', ' Crack'), (' c4', ' Crack'), (' c5', ' Crack'), (' D1', ' Crack'), (' D2', ' Crack'), (' D3', ' Crack'), (' D4', ' Crack'), (' D5', ' Crack'), (' E1', ' Crack'), (' E2', ' Crack'), (' E3', ' Crack'), (' E4', ' Crack'), (' E5', ' Crack'), (' A1', ' Scratch'), (' A2', ' Scratch'), (' A3', ' Scratch'), (' A4', ' Scratch'), (' A5', ' Scratch'), (' B1', ' Scratch'), (' B2', ' Scratch'), (' B3', ' Scratch'), (' B4', ' Scratch'), (' B5', ' Scratch'), (' c1', ' Scratch'), (' c2', ' Scratch'), (' c3', ' Scratch'), (' c4', ' Scratch'), (' c5', ' Scratch'), (' D1', ' Scratch'), (' D2', ' Scratch'), (' D3', ' Scratch'), (' D4', ' Scratch'), (' D5', ' Scratch'), (' E1', ' Scratch'), (' E2', ' Scratch'), (' E3', ' Scratch'), (' E4', ' Scratch'), (' E5', ' Scratch')]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "#note spacing in strings per training data\n",
    "location = [' A1', ' A2', ' A3', ' A4', ' A5', ' B1', ' B2', ' B3', ' B4', ' B5', ' c1', ' c2', ' c3', ' c4', ' c5', ' D1', \\\n",
    "            ' D2', ' D3', ' D4', ' D5', ' E1', ' E2', ' E3', ' E4', ' E5']\n",
    "\n",
    "cause1, cause2 = ' Crack', ' Scratch'\n",
    "\n",
    "cracks, scratches = [], []\n",
    "\n",
    "#create lists of tuples\n",
    "for i in range(len(location)):\n",
    "    tupleObj = (location[i], cause1)\n",
    "    cracks.append(tupleObj)\n",
    "    \n",
    "for i in range(len(location)):\n",
    "    tupleObj = (location[i], cause2)\n",
    "    scratches.append(tupleObj)\n",
    "\n",
    "#concatenate\n",
    "labels = cracks + scratches\n",
    "print(labels)\n",
    "#index of each element will act as the integer label for one hot encoding\n",
    "print(len(labels)) #50\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "missing\n",
      " []\n",
      "\n",
      "\n",
      "train_labels \n",
      " [(33, (' B4', ' Scratch')), (8, (' B4', ' Crack')), (17, (' D3', ' Crack')), (19, (' D5', ' Crack')), (48, (' E4', ' Scratch')), (6, (' B2', ' Crack')), (14, (' c5', ' Crack')), (46, (' E2', ' Scratch')), (42, (' D3', ' Scratch')), (31, (' B2', ' Scratch')), (23, (' E4', ' Crack')), (40, (' D1', ' Scratch')), (36, (' c2', ' Scratch')), (18, (' D4', ' Crack')), (36, (' c2', ' Scratch')), (7, (' B3', ' Crack')), (0, (' A1', ' Crack')), (49, (' E5', ' Scratch')), (7, (' B3', ' Crack')), (26, (' A2', ' Scratch')), (36, (' c2', ' Scratch')), (48, (' E4', ' Scratch')), (40, (' D1', ' Scratch')), (17, (' D3', ' Crack')), (28, (' A4', ' Scratch')), (41, (' D2', ' Scratch')), (12, (' c3', ' Crack')), (35, (' c1', ' Scratch')), (39, (' c5', ' Scratch')), (22, (' E3', ' Crack')), (22, (' E3', ' Crack')), (11, (' c2', ' Crack')), (33, (' B4', ' Scratch')), (13, (' c4', ' Crack')), (27, (' A3', ' Scratch')), (29, (' A5', ' Scratch')), (33, (' B4', ' Scratch')), (37, (' c3', ' Scratch')), (0, (' A1', ' Crack')), (26, (' A2', ' Scratch')), (13, (' c4', ' Crack')), (23, (' E4', ' Crack')), (33, (' B4', ' Scratch')), (22, (' E3', ' Crack')), (5, (' B1', ' Crack')), (11, (' c2', ' Crack')), (17, (' D3', ' Crack')), (42, (' D3', ' Scratch')), (16, (' D2', ' Crack')), (21, (' E2', ' Crack')), (25, (' A1', ' Scratch')), (40, (' D1', ' Scratch')), (20, (' E1', ' Crack')), (9, (' B5', ' Crack')), (36, (' c2', ' Scratch')), (31, (' B2', ' Scratch')), (2, (' A3', ' Crack')), (11, (' c2', ' Crack')), (18, (' D4', ' Crack')), (41, (' D2', ' Scratch')), (31, (' B2', ' Scratch')), (39, (' c5', ' Scratch')), (32, (' B3', ' Scratch')), (23, (' E4', ' Crack')), (26, (' A2', ' Scratch')), (20, (' E1', ' Crack')), (41, (' D2', ' Scratch')), (33, (' B4', ' Scratch')), (8, (' B4', ' Crack')), (14, (' c5', ' Crack')), (40, (' D1', ' Scratch')), (9, (' B5', ' Crack')), (20, (' E1', ' Crack')), (49, (' E5', ' Scratch')), (11, (' c2', ' Crack')), (11, (' c2', ' Crack')), (34, (' B5', ' Scratch')), (20, (' E1', ' Crack')), (9, (' B5', ' Crack')), (10, (' c1', ' Crack')), (38, (' c4', ' Scratch')), (10, (' c1', ' Crack')), (8, (' B4', ' Crack')), (49, (' E5', ' Scratch')), (44, (' D5', ' Scratch')), (38, (' c4', ' Scratch')), (4, (' A5', ' Crack')), (41, (' D2', ' Scratch')), (48, (' E4', ' Scratch')), (29, (' A5', ' Scratch')), (27, (' A3', ' Scratch')), (31, (' B2', ' Scratch')), (25, (' A1', ' Scratch')), (31, (' B2', ' Scratch')), (11, (' c2', ' Crack')), (10, (' c1', ' Crack')), (39, (' c5', ' Scratch')), (26, (' A2', ' Scratch')), (49, (' E5', ' Scratch')), (38, (' c4', ' Scratch')), (35, (' c1', ' Scratch')), (9, (' B5', ' Crack')), (27, (' A3', ' Scratch')), (1, (' A2', ' Crack')), (14, (' c5', ' Crack')), (15, (' D1', ' Crack')), (27, (' A3', ' Scratch')), (22, (' E3', ' Crack')), (40, (' D1', ' Scratch')), (47, (' E3', ' Scratch')), (42, (' D3', ' Scratch')), (43, (' D4', ' Scratch')), (40, (' D1', ' Scratch')), (36, (' c2', ' Scratch')), (16, (' D2', ' Crack')), (42, (' D3', ' Scratch')), (10, (' c1', ' Crack')), (11, (' c2', ' Crack')), (43, (' D4', ' Scratch')), (18, (' D4', ' Crack')), (5, (' B1', ' Crack')), (27, (' A3', ' Scratch')), (3, (' A4', ' Crack')), (35, (' c1', ' Scratch')), (18, (' D4', ' Crack')), (45, (' E1', ' Scratch')), (40, (' D1', ' Scratch')), (12, (' c3', ' Crack')), (41, (' D2', ' Scratch')), (34, (' B5', ' Scratch')), (39, (' c5', ' Scratch')), (10, (' c1', ' Crack')), (42, (' D3', ' Scratch')), (17, (' D3', ' Crack')), (9, (' B5', ' Crack')), (43, (' D4', ' Scratch')), (4, (' A5', ' Crack')), (30, (' B1', ' Scratch')), (8, (' B4', ' Crack')), (17, (' D3', ' Crack')), (39, (' c5', ' Scratch')), (0, (' A1', ' Crack')), (31, (' B2', ' Scratch')), (21, (' E2', ' Crack')), (10, (' c1', ' Crack')), (15, (' D1', ' Crack')), (9, (' B5', ' Crack')), (10, (' c1', ' Crack')), (40, (' D1', ' Scratch')), (0, (' A1', ' Crack'))]\n",
      "\n",
      "\n",
      "train_labels_ints\n",
      " [33, 8, 17, 19, 48, 6, 14, 46, 42, 31, 23, 40, 36, 18, 36, 7, 0, 49, 7, 26, 36, 48, 40, 17, 28, 41, 12, 35, 39, 22, 22, 11, 33, 13, 27, 29, 33, 37, 0, 26, 13, 23, 33, 22, 5, 11, 17, 42, 16, 21, 25, 40, 20, 9, 36, 31, 2, 11, 18, 41, 31, 39, 32, 23, 26, 20, 41, 33, 8, 14, 40, 9, 20, 49, 11, 11, 34, 20, 9, 10, 38, 10, 8, 49, 44, 38, 4, 41, 48, 29, 27, 31, 25, 31, 11, 10, 39, 26, 49, 38, 35, 9, 27, 1, 14, 15, 27, 22, 40, 47, 42, 43, 40, 36, 16, 42, 10, 11, 43, 18, 5, 27, 3, 35, 18, 45, 40, 12, 41, 34, 39, 10, 42, 17, 9, 43, 4, 30, 8, 17, 39, 0, 31, 21, 10, 15, 9, 10, 40, 0]\n",
      "len train labels  150\n",
      "len train_labels_ints 150\n"
     ]
    }
   ],
   "source": [
    "\"\"\"create labels for the train images by iterating through list and looking for matching tuples of \n",
    "location & damage type\"\"\"\n",
    "train_labels = []\n",
    "train_labels_ints = []\n",
    "missing =[]\n",
    "for i in range(len(data_labels)): #len 150\n",
    "    for j in range(len(labels)): #len 50\n",
    "        if data_labels[i] == labels[j]: \n",
    "            tupleObj = (j, data_labels[i])\n",
    "            train_labels.append(tupleObj) #just want the index\n",
    "            train_labels_ints.append(j)\n",
    "\n",
    "#had problems finding C1 because of spacing error...\n",
    "for i in range(len(data_labels)):\n",
    "    if data_labels[i] not in labels:\n",
    "        tupleObj2 = (i, data_labels[i])\n",
    "        missing.append(tupleObj2)\n",
    "print(\"\\n\\nmissing\\n\", missing)\n",
    "print(\"\\n\\ntrain_labels \\n\", train_labels)\n",
    "print(\"\\n\\ntrain_labels_ints\\n\", train_labels_ints)\n",
    "print(\"len train labels \", len(train_labels))\n",
    "print(\"len train_labels_ints\", len(train_labels_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), (' A1', ' Crack')), (array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), (' A2', ' Crack')), (array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), (' A3', ' Crack'))]\n",
      "[array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n",
      "600\n",
      "type of labels_hot and hot_labels\n",
      "\n",
      " <class 'list'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#one hot encode them\n",
    "from keras.utils import np_utils\n",
    "\n",
    "labels_hot = []\n",
    "hot_labels = []\n",
    "for i in range(len(labels)):\n",
    "    hot_label = np_utils.to_categorical(i, 50)\n",
    "    hot_labels.append(hot_label)\n",
    "    tupleObj = (hot_label, labels[i])\n",
    "    labels_hot.append(tupleObj)\n",
    "    \n",
    "#check the first ten one hot labels\n",
    "print(labels_hot[:3]) #tuple version for reference\n",
    "print(hot_labels[:3]) #one-hot only\n",
    "\n",
    "#now one-hot encode training data:\n",
    "train_hots = []\n",
    "for i in range(len(train_labels_ints)):\n",
    "    train_hot = np_utils.to_categorical(train_labels_ints[i], 50)\n",
    "    train_hots.append(train_hot)\n",
    "\n",
    "\n",
    "#need one-hot encodings for the elastic transformation data augmentation \n",
    "onehot_distort1 = train_hots #150 \n",
    "onehot_distort2 = train_hots #150\n",
    "onehot_distort3 = train_hots #150\n",
    "\n",
    "combined_onehot = np.concatenate((train_hots, onehot_distort1, onehot_distort2, onehot_distort3), axis=0 )\n",
    "\n",
    "print(len(combined_onehot))\n",
    "\n",
    "\"\"\"\n",
    "#for MLP\n",
    "y_train = train_hots[:100]\n",
    "y_train = np.array(y_train)\n",
    "y_valid = train_hots[100:130]\n",
    "y_valid = np.array(y_valid)\n",
    "y_test = train_hots[130:]\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"y_train1\\n\\n\", y_train[1])\n",
    "print(\"y_test1\\n\\n\", y_test[1])\n",
    "\"\"\"\n",
    "print(\"type of labels_hot and hot_labels\\n\\n\", type(labels_hot), type(hot_labels))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#test\\nfor i in range(3):\\n    plt.imshow(combined_data[i])\\n    plt.show()\\n    print(combined_onehot[i])\\nfor i in range(3):    \\n    plt.imshow(combined_data[-i-1])\\n    plt.show()\\n    print(combined_onehot[-i-1])\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shuffle and divide into train, valid and test \n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "combined_data, combined_onehot = shuffle(combined_data, combined_onehot)\n",
    "\n",
    "print(len(combined_data), len(combined_onehot))\n",
    "\n",
    "#divided based on formula to use 80% for training and 80/20 split of training data for train/validation\n",
    "x_train = combined_data[:380]\n",
    "x_valid = combined_data[380:480]\n",
    "x_test = combined_data[480:]\n",
    "\n",
    "y_train = combined_onehot[:380]\n",
    "y_valid = combined_onehot[380:480]\n",
    "y_test = combined_onehot[480:]\n",
    "\n",
    "\"\"\"\n",
    "#test\n",
    "for i in range(3):\n",
    "    plt.imshow(combined_data[i])\n",
    "    plt.show()\n",
    "    print(combined_onehot[i])\n",
    "for i in range(3):    \n",
    "    plt.imshow(combined_data[-i-1])\n",
    "    plt.show()\n",
    "    print(combined_onehot[-i-1])\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"save to disk for upload to Colab\n",
    "save new image dataset \n",
    "\"\"\"\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mypath = \"DataSet/DataAndLabels\"\n",
    "if not os.path.isdir(mypath):\n",
    "    os.makedirs(mypath)\n",
    "\n",
    "#save numpy arrays\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "np.save(os.path.join('DataSet/DataAndLabels', 'x_train'), x_train)\n",
    "np.save(os.path.join('DataSet/DataAndLabels', 'x_valid'), x_valid)\n",
    "np.save(os.path.join('DataSet/DataAndLabels', 'x_test'), x_test)\n",
    "np.save(os.path.join('DataSet/DataAndLabels', 'y_train'), y_train)\n",
    "np.save(os.path.join('DataSet/DataAndLabels', 'y_valid'), y_valid)\n",
    "np.save(os.path.join('DataSet/DataAndLabels', 'y_test'), y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the MLP\n",
    "This part was useless.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenlabels 50\n",
      "WARNING:tensorflow:From /home/nobu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/nobu/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/nobu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/nobu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              30721024  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                25650     \n",
      "=================================================================\n",
      "Total params: 31,271,474\n",
      "Trainable params: 31,271,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import adam\n",
    "from keras.regularizers import l1\n",
    "\n",
    "#instantiate regularizer\n",
    "reg = l1(0.001)\n",
    "\n",
    "#2 type of damage * 25 zones = 50\n",
    "num_output_nodes = len(labels)\n",
    "print(\"lenlabels\", len(labels))\n",
    "\n",
    "#define the model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=x_train.shape[1:])) # (100, 100, 3) \n",
    "model.add(Dense(1024, activation='linear', activity_regularizer=l1(0.001)))#512, 1024, 2048, 4096\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) #increase if overfitting\n",
    "model.add(Dense(512, activation='linear', activity_regularizer=l1(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_output_nodes, activation='softmax'))\n",
    "          \n",
    "model.summary()\n",
    "#compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.6667%\n"
     ]
    }
   ],
   "source": [
    "#evaluate test accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "#print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nobu/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 380 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 171894.1788 - acc: 0.0085Epoch 00001: val_loss improved from inf to 93085.71285, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 11s 30ms/step - loss: 165594.5594 - acc: 0.0079 - val_loss: 93085.7129 - val_acc: 0.0200\n",
      "Epoch 2/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 77978.7120 - acc: 0.0114Epoch 00002: val_loss improved from 93085.71285 to 49512.18367, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 10s 27ms/step - loss: 75838.1614 - acc: 0.0132 - val_loss: 49512.1837 - val_acc: 0.0400\n",
      "Epoch 3/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 46362.0916 - acc: 0.0256Epoch 00003: val_loss improved from 49512.18367 to 35866.93059, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 10s 28ms/step - loss: 45578.3491 - acc: 0.0237 - val_loss: 35866.9306 - val_acc: 0.0100\n",
      "Epoch 4/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 36836.5799 - acc: 0.0199Epoch 00004: val_loss improved from 35866.93059 to 29810.84480, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 10s 28ms/step - loss: 36280.3790 - acc: 0.0184 - val_loss: 29810.8448 - val_acc: 0.0100\n",
      "Epoch 5/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 32531.2035 - acc: 0.0114Epoch 00005: val_loss improved from 29810.84480 to 28294.90083, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 11s 29ms/step - loss: 32202.2462 - acc: 0.0105 - val_loss: 28294.9008 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 31827.3567 - acc: 0.0256Epoch 00006: val_loss did not improve\n",
      "380/380 [==============================] - 7s 18ms/step - loss: 31536.3221 - acc: 0.0263 - val_loss: 29421.3645 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 31775.8274 - acc: 0.0170Epoch 00007: val_loss improved from 28294.90083 to 27791.05957, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 11s 30ms/step - loss: 31451.1781 - acc: 0.0184 - val_loss: 27791.0596 - val_acc: 0.0600\n",
      "Epoch 8/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 30798.7612 - acc: 0.0170Epoch 00008: val_loss improved from 27791.05957 to 27042.20835, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 11s 29ms/step - loss: 30454.0288 - acc: 0.0158 - val_loss: 27042.2083 - val_acc: 0.0500\n",
      "Epoch 9/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 30864.7335 - acc: 0.0142Epoch 00009: val_loss did not improve\n",
      "380/380 [==============================] - 7s 19ms/step - loss: 30636.9095 - acc: 0.0132 - val_loss: 29013.1954 - val_acc: 0.0100\n",
      "Epoch 10/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 31371.7669 - acc: 0.0142Epoch 00010: val_loss did not improve\n",
      "380/380 [==============================] - 7s 19ms/step - loss: 31067.9551 - acc: 0.0132 - val_loss: 28297.7689 - val_acc: 0.0200\n",
      "Epoch 11/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 31006.4631 - acc: 0.0142Epoch 00011: val_loss did not improve\n",
      "380/380 [==============================] - 7s 19ms/step - loss: 30718.0992 - acc: 0.0211 - val_loss: 28918.2376 - val_acc: 0.0100\n",
      "Epoch 12/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 31150.8821 - acc: 0.0170Epoch 00012: val_loss did not improve\n",
      "380/380 [==============================] - 8s 22ms/step - loss: 30878.0649 - acc: 0.0184 - val_loss: 28274.5965 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 30826.6229 - acc: 0.0142Epoch 00013: val_loss did not improve\n",
      "380/380 [==============================] - 8s 20ms/step - loss: 30491.6235 - acc: 0.0184 - val_loss: 27800.4626 - val_acc: 0.0300\n",
      "Epoch 14/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 30039.4043 - acc: 0.0284Epoch 00014: val_loss did not improve\n",
      "380/380 [==============================] - 7s 19ms/step - loss: 29797.4888 - acc: 0.0263 - val_loss: 27176.9069 - val_acc: 0.0100\n",
      "Epoch 15/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 30093.6845 - acc: 0.0227Epoch 00015: val_loss did not improve\n",
      "380/380 [==============================] - 7s 19ms/step - loss: 29837.1839 - acc: 0.0211 - val_loss: 27915.0851 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 30251.0968 - acc: 0.0199Epoch 00016: val_loss improved from 27042.20835 to 27008.72264, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 15s 39ms/step - loss: 29981.1421 - acc: 0.0263 - val_loss: 27008.7226 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 29740.8161 - acc: 0.0085Epoch 00017: val_loss improved from 27008.72264 to 27007.29583, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 12s 31ms/step - loss: 29425.4612 - acc: 0.0079 - val_loss: 27007.2958 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 30117.9840 - acc: 0.0114Epoch 00018: val_loss improved from 27007.29583 to 26900.17684, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 12s 32ms/step - loss: 29807.1210 - acc: 0.0105 - val_loss: 26900.1768 - val_acc: 0.0100\n",
      "Epoch 19/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 29725.7211 - acc: 0.0142Epoch 00019: val_loss improved from 26900.17684 to 26595.50236, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 15s 40ms/step - loss: 29421.8740 - acc: 0.0132 - val_loss: 26595.5024 - val_acc: 0.0200\n",
      "Epoch 20/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 29883.5948 - acc: 0.0170Epoch 00020: val_loss did not improve\n",
      "380/380 [==============================] - 8s 20ms/step - loss: 29600.6514 - acc: 0.0158 - val_loss: 27232.6812 - val_acc: 0.0300\n",
      "Epoch 21/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 28958.4688 - acc: 0.0227Epoch 00021: val_loss improved from 26595.50236 to 26036.25871, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 12s 31ms/step - loss: 28642.1728 - acc: 0.0237 - val_loss: 26036.2587 - val_acc: 0.0300\n",
      "Epoch 22/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 28593.8576 - acc: 0.0284Epoch 00022: val_loss did not improve\n",
      "380/380 [==============================] - 8s 21ms/step - loss: 28310.9685 - acc: 0.0289 - val_loss: 26436.8307 - val_acc: 0.0100\n",
      "Epoch 23/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 29592.6003 - acc: 0.0114Epoch 00023: val_loss did not improve\n",
      "380/380 [==============================] - 7s 19ms/step - loss: 29393.1609 - acc: 0.0132 - val_loss: 27106.4268 - val_acc: 0.0300\n",
      "Epoch 24/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 29732.3857 - acc: 0.0341Epoch 00024: val_loss did not improve\n",
      "380/380 [==============================] - 8s 22ms/step - loss: 29429.2853 - acc: 0.0316 - val_loss: 27178.5060 - val_acc: 0.0300\n",
      "Epoch 25/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 29284.3945 - acc: 0.0199Epoch 00025: val_loss did not improve\n",
      "380/380 [==============================] - 8s 21ms/step - loss: 28977.4019 - acc: 0.0211 - val_loss: 26960.4670 - val_acc: 0.0300\n",
      "Epoch 26/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 29170.0320 - acc: 0.0199Epoch 00026: val_loss did not improve\n",
      "380/380 [==============================] - 12s 32ms/step - loss: 28958.3815 - acc: 0.0211 - val_loss: 26918.3552 - val_acc: 0.0300\n",
      "Epoch 27/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28607.6946 - acc: 0.0199Epoch 00027: val_loss did not improve\n",
      "380/380 [==============================] - 20s 54ms/step - loss: 28329.8453 - acc: 0.0211 - val_loss: 26177.0154 - val_acc: 0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 29063.7480 - acc: 0.0085Epoch 00028: val_loss did not improve\n",
      "380/380 [==============================] - 19s 51ms/step - loss: 28839.8001 - acc: 0.0105 - val_loss: 27192.4911 - val_acc: 0.0300\n",
      "Epoch 29/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 29135.9402 - acc: 0.0170Epoch 00029: val_loss did not improve\n",
      "380/380 [==============================] - 20s 53ms/step - loss: 28813.3459 - acc: 0.0184 - val_loss: 26272.8370 - val_acc: 0.0100\n",
      "Epoch 30/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28999.1415 - acc: 0.0199Epoch 00030: val_loss did not improve\n",
      "380/380 [==============================] - 18s 47ms/step - loss: 28716.2426 - acc: 0.0184 - val_loss: 27272.0806 - val_acc: 0.0100\n",
      "Epoch 31/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28909.8468 - acc: 0.0256Epoch 00031: val_loss did not improve\n",
      "380/380 [==============================] - 17s 46ms/step - loss: 28578.5620 - acc: 0.0263 - val_loss: 26500.7607 - val_acc: 0.0200\n",
      "Epoch 32/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28302.9158 - acc: 0.0114Epoch 00032: val_loss improved from 26036.25871 to 25635.59521, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 28s 73ms/step - loss: 28039.8424 - acc: 0.0158 - val_loss: 25635.5952 - val_acc: 0.0300\n",
      "Epoch 33/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28325.5953 - acc: 0.0284Epoch 00033: val_loss did not improve\n",
      "380/380 [==============================] - 18s 46ms/step - loss: 28085.5845 - acc: 0.0263 - val_loss: 26373.0210 - val_acc: 0.0300\n",
      "Epoch 34/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28339.6282 - acc: 0.0114Epoch 00034: val_loss did not improve\n",
      "380/380 [==============================] - 20s 51ms/step - loss: 28022.9646 - acc: 0.0132 - val_loss: 26423.3524 - val_acc: 0.0200\n",
      "Epoch 35/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28292.6456 - acc: 0.0114Epoch 00035: val_loss did not improve\n",
      "380/380 [==============================] - 18s 48ms/step - loss: 28051.3866 - acc: 0.0105 - val_loss: 26558.5098 - val_acc: 0.0200\n",
      "Epoch 36/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28211.4226 - acc: 0.0227Epoch 00036: val_loss did not improve\n",
      "380/380 [==============================] - 17s 46ms/step - loss: 27937.3164 - acc: 0.0211 - val_loss: 26859.1685 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28723.3091 - acc: 0.0170Epoch 00037: val_loss did not improve\n",
      "380/380 [==============================] - 16s 41ms/step - loss: 28407.8817 - acc: 0.0211 - val_loss: 25691.7240 - val_acc: 0.0300\n",
      "Epoch 38/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27765.3572 - acc: 0.0199Epoch 00038: val_loss improved from 25635.59521 to 25317.74139, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 19s 50ms/step - loss: 27455.7479 - acc: 0.0184 - val_loss: 25317.7414 - val_acc: 0.0200\n",
      "Epoch 39/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27623.7873 - acc: 0.0341Epoch 00039: val_loss did not improve\n",
      "380/380 [==============================] - 15s 41ms/step - loss: 27302.1642 - acc: 0.0316 - val_loss: 25367.6943 - val_acc: 0.0100\n",
      "Epoch 40/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27700.1026 - acc: 0.0227Epoch 00040: val_loss improved from 25317.74139 to 24985.33248, saving model to detector.model.best.hdf5\n",
      "380/380 [==============================] - 19s 50ms/step - loss: 27449.5230 - acc: 0.0237 - val_loss: 24985.3325 - val_acc: 0.0300\n",
      "Epoch 41/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28075.8825 - acc: 0.0085Epoch 00041: val_loss did not improve\n",
      "380/380 [==============================] - 16s 41ms/step - loss: 27847.8160 - acc: 0.0105 - val_loss: 26234.6913 - val_acc: 0.0300\n",
      "Epoch 42/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28187.3063 - acc: 0.0312Epoch 00042: val_loss did not improve\n",
      "380/380 [==============================] - 15s 41ms/step - loss: 27916.5787 - acc: 0.0316 - val_loss: 26427.9476 - val_acc: 0.0300\n",
      "Epoch 43/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27280.0712 - acc: 0.0312Epoch 00043: val_loss did not improve\n",
      "380/380 [==============================] - 16s 41ms/step - loss: 27038.0106 - acc: 0.0289 - val_loss: 25323.1516 - val_acc: 0.0300\n",
      "Epoch 44/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27182.9819 - acc: 0.0227Epoch 00044: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 26918.1111 - acc: 0.0237 - val_loss: 26209.6794 - val_acc: 0.0300\n",
      "Epoch 45/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27505.5996 - acc: 0.0256Epoch 00045: val_loss did not improve\n",
      "380/380 [==============================] - 16s 43ms/step - loss: 27246.8929 - acc: 0.0237 - val_loss: 25397.8005 - val_acc: 0.0300\n",
      "Epoch 46/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27480.2278 - acc: 0.0341Epoch 00046: val_loss did not improve\n",
      "380/380 [==============================] - 17s 45ms/step - loss: 27221.4787 - acc: 0.0316 - val_loss: 26629.3641 - val_acc: 0.0300\n",
      "Epoch 47/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28020.6477 - acc: 0.0341Epoch 00047: val_loss did not improve\n",
      "380/380 [==============================] - 18s 48ms/step - loss: 27761.8789 - acc: 0.0342 - val_loss: 26884.7970 - val_acc: 0.0300\n",
      "Epoch 48/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27825.0762 - acc: 0.0199Epoch 00048: val_loss did not improve\n",
      "380/380 [==============================] - 16s 43ms/step - loss: 27575.2943 - acc: 0.0184 - val_loss: 25263.1016 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27182.7418 - acc: 0.0170Epoch 00049: val_loss did not improve\n",
      "380/380 [==============================] - 16s 41ms/step - loss: 26924.5037 - acc: 0.0237 - val_loss: 25021.5033 - val_acc: 0.0300\n",
      "Epoch 50/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27724.5060 - acc: 0.0284Epoch 00050: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 27500.9883 - acc: 0.0289 - val_loss: 25781.0609 - val_acc: 0.0300\n",
      "Epoch 51/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27894.4952 - acc: 0.0256Epoch 00051: val_loss did not improve\n",
      "380/380 [==============================] - 16s 43ms/step - loss: 27694.5063 - acc: 0.0237 - val_loss: 25917.5384 - val_acc: 0.0300\n",
      "Epoch 52/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27673.9137 - acc: 0.0256Epoch 00052: val_loss did not improve\n",
      "380/380 [==============================] - 17s 44ms/step - loss: 27401.4436 - acc: 0.0263 - val_loss: 26196.3232 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27814.9597 - acc: 0.0341Epoch 00053: val_loss did not improve\n",
      "380/380 [==============================] - 16s 43ms/step - loss: 27576.5909 - acc: 0.0316 - val_loss: 26250.4413 - val_acc: 0.0300\n",
      "Epoch 54/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27816.7647 - acc: 0.0256Epoch 00054: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 27628.4199 - acc: 0.0263 - val_loss: 25959.2534 - val_acc: 0.0300\n",
      "Epoch 55/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27909.0124 - acc: 0.0256Epoch 00055: val_loss did not improve\n",
      "380/380 [==============================] - 17s 44ms/step - loss: 27607.9538 - acc: 0.0263 - val_loss: 25606.3460 - val_acc: 0.0300\n",
      "Epoch 56/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27995.5254 - acc: 0.0284Epoch 00056: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 27829.7910 - acc: 0.0263 - val_loss: 26800.0877 - val_acc: 0.0300\n",
      "Epoch 57/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28414.6319 - acc: 0.0284Epoch 00057: val_loss did not improve\n",
      "380/380 [==============================] - 17s 45ms/step - loss: 28156.6103 - acc: 0.0289 - val_loss: 26828.9139 - val_acc: 0.0300\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/380 [==========================>...] - ETA: 1s - loss: 27919.6825 - acc: 0.0227Epoch 00058: val_loss did not improve\n",
      "380/380 [==============================] - 17s 44ms/step - loss: 27668.7559 - acc: 0.0237 - val_loss: 26344.5450 - val_acc: 0.0100\n",
      "Epoch 59/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27771.9197 - acc: 0.0312Epoch 00059: val_loss did not improve\n",
      "380/380 [==============================] - 17s 46ms/step - loss: 27600.6408 - acc: 0.0316 - val_loss: 26846.6419 - val_acc: 0.0100\n",
      "Epoch 60/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27853.1199 - acc: 0.0227Epoch 00060: val_loss did not improve\n",
      "380/380 [==============================] - 18s 48ms/step - loss: 27636.5092 - acc: 0.0263 - val_loss: 26466.6896 - val_acc: 0.0100\n",
      "Epoch 61/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27767.6944 - acc: 0.0369Epoch 00061: val_loss did not improve\n",
      "380/380 [==============================] - 18s 46ms/step - loss: 27443.6165 - acc: 0.0342 - val_loss: 25602.1697 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27503.6635 - acc: 0.0227Epoch 00062: val_loss did not improve\n",
      "380/380 [==============================] - 17s 44ms/step - loss: 27216.2314 - acc: 0.0237 - val_loss: 25913.8676 - val_acc: 0.0300\n",
      "Epoch 63/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27574.9187 - acc: 0.0199Epoch 00063: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 27301.0288 - acc: 0.0184 - val_loss: 25803.6204 - val_acc: 0.0500\n",
      "Epoch 64/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27700.8567 - acc: 0.0227Epoch 00064: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 27499.7123 - acc: 0.0289 - val_loss: 27003.3814 - val_acc: 0.0300\n",
      "Epoch 65/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27605.6909 - acc: 0.0312Epoch 00065: val_loss did not improve\n",
      "380/380 [==============================] - 16s 43ms/step - loss: 27386.6699 - acc: 0.0316 - val_loss: 25982.0363 - val_acc: 0.0500\n",
      "Epoch 66/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27489.4879 - acc: 0.0227Epoch 00066: val_loss did not improve\n",
      "380/380 [==============================] - 16s 43ms/step - loss: 27309.9675 - acc: 0.0263 - val_loss: 25927.6154 - val_acc: 0.0500\n",
      "Epoch 67/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27828.6026 - acc: 0.0170Epoch 00067: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 27590.2082 - acc: 0.0184 - val_loss: 25956.6854 - val_acc: 0.0500\n",
      "Epoch 68/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27881.7338 - acc: 0.0341Epoch 00068: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 27626.2814 - acc: 0.0342 - val_loss: 26424.3019 - val_acc: 0.0500\n",
      "Epoch 69/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28269.3960 - acc: 0.0284Epoch 00069: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 28023.2281 - acc: 0.0289 - val_loss: 26945.8594 - val_acc: 0.0500\n",
      "Epoch 70/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28541.1078 - acc: 0.0284Epoch 00070: val_loss did not improve\n",
      "380/380 [==============================] - 17s 44ms/step - loss: 28296.5979 - acc: 0.0263 - val_loss: 26608.0828 - val_acc: 0.0500\n",
      "Epoch 71/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28088.9645 - acc: 0.0284Epoch 00071: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 27850.9565 - acc: 0.0342 - val_loss: 27936.7207 - val_acc: 0.0300\n",
      "Epoch 72/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28306.3485 - acc: 0.0256Epoch 00072: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 28023.8850 - acc: 0.0263 - val_loss: 27108.2991 - val_acc: 0.0500\n",
      "Epoch 73/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27999.7411 - acc: 0.0398Epoch 00073: val_loss did not improve\n",
      "380/380 [==============================] - 17s 44ms/step - loss: 27742.7845 - acc: 0.0368 - val_loss: 27497.2372 - val_acc: 0.0500\n",
      "Epoch 74/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27849.1484 - acc: 0.0199Epoch 00074: val_loss did not improve\n",
      "380/380 [==============================] - 16s 43ms/step - loss: 27605.4136 - acc: 0.0211 - val_loss: 26264.6217 - val_acc: 0.0100\n",
      "Epoch 75/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27771.1680 - acc: 0.0341Epoch 00075: val_loss did not improve\n",
      "380/380 [==============================] - 16s 42ms/step - loss: 27530.5539 - acc: 0.0368 - val_loss: 25547.0269 - val_acc: 0.0500\n",
      "Epoch 76/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 27615.4689 - acc: 0.0284Epoch 00076: val_loss did not improve\n",
      "380/380 [==============================] - 16s 43ms/step - loss: 27371.0106 - acc: 0.0263 - val_loss: 26523.9445 - val_acc: 0.0500\n",
      "Epoch 77/100\n",
      "352/380 [==========================>...] - ETA: 1s - loss: 28056.3295 - acc: 0.0341Epoch 00077: val_loss did not improve\n",
      "380/380 [==============================] - 17s 44ms/step - loss: 27812.9309 - acc: 0.0342 - val_loss: 26429.3512 - val_acc: 0.0100\n",
      "Epoch 78/100\n",
      "192/380 [==============>...............] - ETA: 8s - loss: 28358.6748 - acc: 0.0156"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-85c66e8901bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'detector.model.best.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#train the model\n",
    "checkpointer = ModelCheckpoint(filepath='detector.model.best.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_valid, y_valid), callbacks=[checkpointer], \\\n",
    "                verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('detector.model.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the classification accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s 4ms/step\n",
      "Test accuracy: 2.5000%\n"
     ]
    }
   ],
   "source": [
    "#evaluate test accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "#print test accuracy\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:  \n",
    "Should have tried CNN transfer learning first..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras CNN\n",
    "This was also pretty bad..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data\n",
    "\n",
    "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, \\text{rows}, \\text{columns}, \\text{channels}),\n",
    "$$\n",
    "\n",
    "where `nb_samples` corresponds to the total number of images (or samples), and `rows`, `columns`, and `channels` correspond to the number of rows, columns, and channels for each image, respectively.  \n",
    "\n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "Here, `nb_samples` is the number of samples, or number of images, in the supplied array of image paths.  It is best to think of `nb_samples` as the number of 3D tensors (where each 3D tensor corresponds to a different image) in your dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "Can skip this section as it was before the transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "30\n",
      "20\n",
      "100\n",
      "30\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#check len of datasets\n",
    "print(len(x_train))\n",
    "print(len(x_valid))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_valid))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#divide into train, valid and test for CNN\n",
    "x_valid = x_train[100:] #30 samples\n",
    "x_train = x_train[:100]\n",
    "x_test = x_test\n",
    "\n",
    "print(len(x_valid), len(x_train))\n",
    "y_valid = y_train[100:] \n",
    "y_train = y_train[:100]\n",
    "y_test = y_test\n",
    "\"\"\"\n",
    "\n",
    "#reshape\n",
    "x_train = x_train.reshape(100, 100, 100, 3)\n",
    "x_valid = x_valid.reshape(30, 100, 100, 3)\n",
    "x_test = x_test.reshape(20, 100, 100, 3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 98, 98, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 49, 49, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 49, 49, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 47, 47, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 21, 21, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1, 1, 256)         16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1, 1, 50)          12850     \n",
      "=================================================================\n",
      "Total params: 100,274\n",
      "Trainable params: 99,762\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D \n",
    "from keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=3, padding='valid', activation='relu', \\\n",
    "                 input_shape=(100,100,3))) #none means any (nb_samples, rows, cols, channels)\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.7))\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(len(labels), activation='softmax')) #50 output nodes\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_53 to have 4 dimensions, but got array with shape (100, 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-0cd39382d79a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_53 to have 4 dimensions, but got array with shape (100, 50)"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 100\n",
    "batch_size= 32\n",
    "\n",
    "filepath=\"weights.best.from_scratch_cnn.hdf5\"\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=epochs, batch_size=batch_size, \\\n",
    "         callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model with Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.best.from_scratch_cnn.hdf5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model \n",
    "I am pretty sure I need to use image augmentation and maybe transfer learning from Resnet50 or VGG 16, etc to get 80% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.0000%\n"
     ]
    }
   ],
   "source": [
    "#get index of predicted zone and type of damage for each image in test set\n",
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in x_test]\n",
    "\n",
    "#report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(predictions)==np.argmax(y_test, axis=1))/len(predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Configure Augmented Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#create and configure augmented image generator\n",
    "datagen_train = ImageDataGenerator(width_shift_range=-0.1, height_shift_range=-0.1, horizontal_flip=True, \\\n",
    "                                  vertical_flip=True)\n",
    "\n",
    "#fit augmented image generator on data\n",
    "datagen_train.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# take subset of training data\n",
    "x_train_subset = x_train[:12]\n",
    "\n",
    "# visualize subset of training data\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "for i in range(0, len(x_train_subset)):\n",
    "    ax = fig.add_subplot(1, 12, i+1)\n",
    "    ax.imshow(x_train_subset[i])\n",
    "fig.suptitle('Subset of Original Training Images', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# visualize augmented images\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "for x_batch in datagen_train.flow(x_train_subset, batch_size=12):\n",
    "    for i in range(0, 12):\n",
    "        ax = fig.add_subplot(1, 12, i+1)\n",
    "        ax.imshow(x_batch[i])\n",
    "    fig.suptitle('Augmented Images', fontsize=20)\n",
    "    plt.show()\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 00001: val_loss improved from inf to 3.25434, saving model to augment_model.weights.best.hdf5\n",
      " - 11s - loss: 6.0189 - acc: 0.1466 - val_loss: 3.2543 - val_acc: 0.3667\n",
      "Epoch 2/100\n",
      "Epoch 00002: val_loss did not improve\n",
      " - 9s - loss: 6.5908 - acc: 0.0833 - val_loss: 3.4953 - val_acc: 0.2333\n",
      "Epoch 3/100\n",
      "Epoch 00003: val_loss did not improve\n",
      " - 7s - loss: 5.1302 - acc: 0.1494 - val_loss: 3.8305 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "Epoch 00004: val_loss did not improve\n",
      " - 7s - loss: 3.7500 - acc: 0.1581 - val_loss: 4.0000 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "Epoch 00005: val_loss did not improve\n",
      " - 7s - loss: 3.6962 - acc: 0.1149 - val_loss: 4.0267 - val_acc: 0.1000\n",
      "Epoch 6/100\n",
      "Epoch 00006: val_loss did not improve\n",
      " - 7s - loss: 3.5809 - acc: 0.0919 - val_loss: 4.0383 - val_acc: 0.1000\n",
      "Epoch 7/100\n",
      "Epoch 00007: val_loss did not improve\n",
      " - 9s - loss: 3.6716 - acc: 0.1146 - val_loss: 4.0446 - val_acc: 0.1000\n",
      "Epoch 8/100\n",
      "Epoch 00008: val_loss did not improve\n",
      " - 7s - loss: 3.6143 - acc: 0.0574 - val_loss: 4.0606 - val_acc: 0.1000\n",
      "Epoch 9/100\n",
      "Epoch 00009: val_loss did not improve\n",
      " - 6s - loss: 3.5317 - acc: 0.1466 - val_loss: 4.0719 - val_acc: 0.1000\n",
      "Epoch 10/100\n",
      "Epoch 00010: val_loss did not improve\n",
      " - 8s - loss: 3.5846 - acc: 0.0729 - val_loss: 4.0635 - val_acc: 0.1000\n",
      "Epoch 11/100\n",
      "Epoch 00011: val_loss did not improve\n",
      " - 7s - loss: 3.6816 - acc: 0.1696 - val_loss: 3.9759 - val_acc: 0.1000\n",
      "Epoch 12/100\n",
      "Epoch 00012: val_loss did not improve\n",
      " - 7s - loss: 3.4605 - acc: 0.0574 - val_loss: 4.0884 - val_acc: 0.1000\n",
      "Epoch 13/100\n",
      "Epoch 00013: val_loss did not improve\n",
      " - 7s - loss: 3.4664 - acc: 0.0804 - val_loss: 4.0947 - val_acc: 0.1333\n",
      "Epoch 14/100\n",
      "Epoch 00014: val_loss did not improve\n",
      " - 8s - loss: 3.2332 - acc: 0.2083 - val_loss: 4.0960 - val_acc: 0.1333\n",
      "Epoch 15/100\n",
      "Epoch 00015: val_loss did not improve\n",
      " - 6s - loss: 3.4021 - acc: 0.0574 - val_loss: 4.0956 - val_acc: 0.1667\n",
      "Epoch 16/100\n",
      "Epoch 00016: val_loss did not improve\n",
      " - 6s - loss: 3.1834 - acc: 0.2270 - val_loss: 4.0803 - val_acc: 0.1667\n",
      "Epoch 17/100\n",
      "Epoch 00017: val_loss did not improve\n",
      " - 7s - loss: 3.1417 - acc: 0.1696 - val_loss: 4.0431 - val_acc: 0.1667\n",
      "Epoch 18/100\n",
      "Epoch 00018: val_loss did not improve\n",
      " - 9s - loss: 3.2052 - acc: 0.1875 - val_loss: 4.0192 - val_acc: 0.1667\n",
      "Epoch 19/100\n",
      "Epoch 00019: val_loss did not improve\n",
      " - 5s - loss: 3.9290 - acc: 0.1250 - val_loss: 4.0129 - val_acc: 0.1667\n",
      "Epoch 20/100\n",
      "Epoch 00020: val_loss did not improve\n",
      " - 8s - loss: 3.2313 - acc: 0.1771 - val_loss: 4.0362 - val_acc: 0.1667\n",
      "Epoch 21/100\n",
      "Epoch 00021: val_loss did not improve\n",
      " - 8s - loss: 3.2115 - acc: 0.1562 - val_loss: 4.0358 - val_acc: 0.1000\n",
      "Epoch 22/100\n",
      "Epoch 00022: val_loss did not improve\n",
      " - 5s - loss: 3.0836 - acc: 0.1797 - val_loss: 4.0306 - val_acc: 0.1000\n",
      "Epoch 23/100\n",
      "Epoch 00023: val_loss did not improve\n",
      " - 10s - loss: 3.2735 - acc: 0.1042 - val_loss: 4.0437 - val_acc: 0.1000\n",
      "Epoch 24/100\n",
      "Epoch 00024: val_loss did not improve\n",
      " - 9s - loss: 3.0658 - acc: 0.2270 - val_loss: 4.0421 - val_acc: 0.1000\n",
      "Epoch 25/100\n",
      "Epoch 00025: val_loss did not improve\n",
      " - 8s - loss: 3.0902 - acc: 0.2183 - val_loss: 4.0269 - val_acc: 0.1000\n",
      "Epoch 26/100\n",
      "Epoch 00026: val_loss did not improve\n",
      " - 11s - loss: 2.9670 - acc: 0.2708 - val_loss: 3.9872 - val_acc: 0.2000\n",
      "Epoch 27/100\n",
      "Epoch 00027: val_loss did not improve\n",
      " - 9s - loss: 2.7425 - acc: 0.2385 - val_loss: 3.9882 - val_acc: 0.2000\n",
      "Epoch 28/100\n",
      "Epoch 00028: val_loss did not improve\n",
      " - 9s - loss: 3.1545 - acc: 0.1723 - val_loss: 4.0101 - val_acc: 0.1667\n",
      "Epoch 29/100\n",
      "Epoch 00029: val_loss did not improve\n",
      " - 11s - loss: 3.0825 - acc: 0.1875 - val_loss: 4.0028 - val_acc: 0.1667\n",
      "Epoch 30/100\n",
      "Epoch 00030: val_loss did not improve\n",
      " - 7s - loss: 2.7205 - acc: 0.2922 - val_loss: 3.8707 - val_acc: 0.1667\n",
      "Epoch 31/100\n",
      "Epoch 00031: val_loss did not improve\n",
      " - 10s - loss: 2.9429 - acc: 0.1953 - val_loss: 4.6418 - val_acc: 0.0333\n",
      "Epoch 32/100\n",
      "Epoch 00032: val_loss did not improve\n",
      " - 11s - loss: 3.0798 - acc: 0.1979 - val_loss: 3.6159 - val_acc: 0.2000\n",
      "Epoch 33/100\n",
      "Epoch 00033: val_loss did not improve\n",
      " - 7s - loss: 2.7639 - acc: 0.2932 - val_loss: 3.6266 - val_acc: 0.2333\n",
      "Epoch 34/100\n",
      "Epoch 00034: val_loss did not improve\n",
      " - 8s - loss: 2.9154 - acc: 0.2083 - val_loss: 3.5204 - val_acc: 0.3000\n",
      "Epoch 35/100\n",
      "Epoch 00035: val_loss did not improve\n",
      " - 7s - loss: 3.2350 - acc: 0.2155 - val_loss: 3.6032 - val_acc: 0.2667\n",
      "Epoch 36/100\n",
      "Epoch 00036: val_loss did not improve\n",
      " - 7s - loss: 2.8033 - acc: 0.2155 - val_loss: 3.7455 - val_acc: 0.2333\n",
      "Epoch 37/100\n",
      "Epoch 00037: val_loss did not improve\n",
      " - 8s - loss: 2.7130 - acc: 0.2730 - val_loss: 3.7907 - val_acc: 0.2333\n",
      "Epoch 38/100\n",
      "Epoch 00038: val_loss did not improve\n",
      " - 8s - loss: 2.8782 - acc: 0.2292 - val_loss: 3.7578 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "Epoch 00039: val_loss did not improve\n",
      " - 7s - loss: 3.3958 - acc: 0.1379 - val_loss: 3.7434 - val_acc: 0.2667\n",
      "Epoch 40/100\n",
      "Epoch 00040: val_loss did not improve\n",
      " - 7s - loss: 2.9142 - acc: 0.1723 - val_loss: 3.8109 - val_acc: 0.2333\n",
      "Epoch 41/100\n",
      "Epoch 00041: val_loss did not improve\n",
      " - 7s - loss: 2.9187 - acc: 0.2932 - val_loss: 3.8428 - val_acc: 0.2333\n",
      "Epoch 42/100\n",
      "Epoch 00042: val_loss did not improve\n",
      " - 9s - loss: 3.0842 - acc: 0.1875 - val_loss: 3.9069 - val_acc: 0.2000\n",
      "Epoch 43/100\n",
      "Epoch 00043: val_loss did not improve\n",
      " - 7s - loss: 2.5935 - acc: 0.3162 - val_loss: 3.9359 - val_acc: 0.1333\n",
      "Epoch 44/100\n",
      "Epoch 00044: val_loss did not improve\n",
      " - 7s - loss: 2.7205 - acc: 0.1494 - val_loss: 3.8453 - val_acc: 0.1333\n",
      "Epoch 45/100\n",
      "Epoch 00045: val_loss did not improve\n",
      " - 6s - loss: 2.7801 - acc: 0.1723 - val_loss: 3.7354 - val_acc: 0.2000\n",
      "Epoch 46/100\n",
      "Epoch 00046: val_loss did not improve\n",
      " - 8s - loss: 2.6907 - acc: 0.2188 - val_loss: 3.6911 - val_acc: 0.2333\n",
      "Epoch 47/100\n",
      "Epoch 00047: val_loss did not improve\n",
      " - 7s - loss: 2.5432 - acc: 0.4168 - val_loss: 3.6755 - val_acc: 0.2000\n",
      "Epoch 48/100\n",
      "Epoch 00048: val_loss did not improve\n",
      " - 6s - loss: 2.4937 - acc: 0.2845 - val_loss: 3.6171 - val_acc: 0.2000\n",
      "Epoch 49/100\n",
      "Epoch 00049: val_loss did not improve\n",
      " - 6s - loss: 3.0040 - acc: 0.1149 - val_loss: 3.5868 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "Epoch 00050: val_loss did not improve\n",
      " - 8s - loss: 2.9681 - acc: 0.2183 - val_loss: 4.2233 - val_acc: 0.1333\n",
      "Epoch 51/100\n",
      "Epoch 00051: val_loss did not improve\n",
      " - 7s - loss: 2.4472 - acc: 0.3966 - val_loss: 3.5358 - val_acc: 0.3000\n",
      "Epoch 52/100\n",
      "Epoch 00052: val_loss did not improve\n",
      " - 10s - loss: 2.6854 - acc: 0.2188 - val_loss: 3.4864 - val_acc: 0.2333\n",
      "Epoch 53/100\n",
      "Epoch 00053: val_loss did not improve\n",
      " - 8s - loss: 3.0934 - acc: 0.2528 - val_loss: 3.4988 - val_acc: 0.2333\n",
      "Epoch 54/100\n",
      "Epoch 00054: val_loss did not improve\n",
      " - 9s - loss: 2.5618 - acc: 0.2730 - val_loss: 4.8026 - val_acc: 0.0667\n",
      "Epoch 55/100\n",
      "Epoch 00055: val_loss did not improve\n",
      " - 9s - loss: 2.4930 - acc: 0.3646 - val_loss: 3.5089 - val_acc: 0.1667\n",
      "Epoch 56/100\n",
      "Epoch 00056: val_loss did not improve\n",
      " - 7s - loss: 2.8519 - acc: 0.2298 - val_loss: 3.5676 - val_acc: 0.2333\n",
      "Epoch 57/100\n",
      "Epoch 00057: val_loss did not improve\n",
      " - 7s - loss: 2.4349 - acc: 0.2845 - val_loss: 3.4808 - val_acc: 0.2333\n",
      "Epoch 58/100\n",
      "Epoch 00058: val_loss did not improve\n",
      " - 7s - loss: 2.8494 - acc: 0.1838 - val_loss: 3.4725 - val_acc: 0.1667\n",
      "Epoch 59/100\n",
      "Epoch 00059: val_loss did not improve\n",
      " - 8s - loss: 2.1981 - acc: 0.3958 - val_loss: 3.4525 - val_acc: 0.2333\n",
      "Epoch 60/100\n",
      "Epoch 00060: val_loss did not improve\n",
      " - 6s - loss: 2.3221 - acc: 0.3736 - val_loss: 3.4269 - val_acc: 0.2000\n",
      "Epoch 61/100\n",
      "Epoch 00061: val_loss did not improve\n",
      " - 7s - loss: 2.4927 - acc: 0.3047 - val_loss: 3.4805 - val_acc: 0.2333\n",
      "Epoch 62/100\n",
      "Epoch 00062: val_loss did not improve\n",
      " - 6s - loss: 2.3860 - acc: 0.3736 - val_loss: 3.5764 - val_acc: 0.2333\n",
      "Epoch 63/100\n",
      "Epoch 00063: val_loss did not improve\n",
      " - 7s - loss: 2.7396 - acc: 0.2500 - val_loss: 3.6167 - val_acc: 0.2000\n",
      "Epoch 64/100\n",
      "Epoch 00064: val_loss did not improve\n",
      " - 8s - loss: 2.5232 - acc: 0.3229 - val_loss: 3.6581 - val_acc: 0.2000\n",
      "Epoch 65/100\n",
      "Epoch 00065: val_loss did not improve\n",
      " - 7s - loss: 2.9536 - acc: 0.2068 - val_loss: 3.6459 - val_acc: 0.2000\n",
      "Epoch 66/100\n",
      "Epoch 00066: val_loss did not improve\n",
      " - 7s - loss: 2.8897 - acc: 0.2845 - val_loss: 7.0406 - val_acc: 0.0333\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00067: val_loss did not improve\n",
      " - 10s - loss: 2.2538 - acc: 0.3958 - val_loss: 4.7548 - val_acc: 0.1000\n",
      "Epoch 68/100\n",
      "Epoch 00068: val_loss did not improve\n",
      " - 7s - loss: 2.2688 - acc: 0.3736 - val_loss: 3.5956 - val_acc: 0.2333\n",
      "Epoch 69/100\n",
      "Epoch 00069: val_loss did not improve\n",
      " - 8s - loss: 2.4291 - acc: 0.3304 - val_loss: 3.7180 - val_acc: 0.2333\n",
      "Epoch 70/100\n",
      "Epoch 00070: val_loss did not improve\n",
      " - 7s - loss: 2.6336 - acc: 0.2528 - val_loss: 4.0114 - val_acc: 0.0667\n",
      "Epoch 71/100\n",
      "Epoch 00071: val_loss did not improve\n",
      " - 9s - loss: 2.5227 - acc: 0.3021 - val_loss: 4.2885 - val_acc: 0.1333\n",
      "Epoch 72/100\n",
      "Epoch 00072: val_loss did not improve\n",
      " - 7s - loss: 2.5353 - acc: 0.2068 - val_loss: 4.2945 - val_acc: 0.1333\n",
      "Epoch 73/100\n",
      "Epoch 00073: val_loss did not improve\n",
      " - 8s - loss: 2.6049 - acc: 0.2270 - val_loss: 4.0722 - val_acc: 0.1667\n",
      "Epoch 74/100\n",
      "Epoch 00074: val_loss did not improve\n",
      " - 8s - loss: 2.5535 - acc: 0.3074 - val_loss: 3.9159 - val_acc: 0.1667\n",
      "Epoch 75/100\n",
      "Epoch 00075: val_loss did not improve\n",
      " - 10s - loss: 2.3051 - acc: 0.2917 - val_loss: 3.8120 - val_acc: 0.2333\n",
      "Epoch 76/100\n",
      "Epoch 00076: val_loss did not improve\n",
      " - 9s - loss: 2.6030 - acc: 0.2960 - val_loss: 3.6442 - val_acc: 0.2667\n",
      "Epoch 77/100\n",
      "Epoch 00077: val_loss did not improve\n",
      " - 11s - loss: 2.4025 - acc: 0.3333 - val_loss: 3.5902 - val_acc: 0.2667\n",
      "Epoch 78/100\n",
      "Epoch 00078: val_loss did not improve\n",
      " - 5s - loss: 2.0110 - acc: 0.4297 - val_loss: 3.5340 - val_acc: 0.2667\n",
      "Epoch 79/100\n",
      "Epoch 00079: val_loss did not improve\n",
      " - 7s - loss: 2.6220 - acc: 0.1838 - val_loss: 3.4403 - val_acc: 0.3333\n",
      "Epoch 80/100\n",
      "Epoch 00080: val_loss did not improve\n",
      " - 9s - loss: 2.3222 - acc: 0.3229 - val_loss: 3.4167 - val_acc: 0.3000\n",
      "Epoch 81/100\n",
      "Epoch 00081: val_loss did not improve\n",
      " - 7s - loss: 2.3640 - acc: 0.3764 - val_loss: 3.4184 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "Epoch 00082: val_loss did not improve\n",
      " - 8s - loss: 2.1642 - acc: 0.3438 - val_loss: 3.4157 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "Epoch 00083: val_loss did not improve\n",
      " - 6s - loss: 2.3252 - acc: 0.3506 - val_loss: 3.4531 - val_acc: 0.2667\n",
      "Epoch 84/100\n",
      "Epoch 00084: val_loss did not improve\n",
      " - 7s - loss: 2.4967 - acc: 0.2183 - val_loss: 3.4616 - val_acc: 0.2333\n",
      "Epoch 85/100\n",
      "Epoch 00085: val_loss did not improve\n",
      " - 5s - loss: 2.4811 - acc: 0.2413 - val_loss: 3.4952 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "Epoch 00086: val_loss did not improve\n",
      " - 8s - loss: 2.3036 - acc: 0.3229 - val_loss: 3.4784 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "Epoch 00087: val_loss did not improve\n",
      " - 6s - loss: 2.3993 - acc: 0.2642 - val_loss: 3.4594 - val_acc: 0.1667\n",
      "Epoch 88/100\n",
      "Epoch 00088: val_loss did not improve\n",
      " - 7s - loss: 2.6680 - acc: 0.2183 - val_loss: 3.4389 - val_acc: 0.1667\n",
      "Epoch 89/100\n",
      "Epoch 00089: val_loss did not improve\n",
      " - 7s - loss: 2.1132 - acc: 0.4081 - val_loss: 3.4597 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "Epoch 00090: val_loss did not improve\n",
      " - 7s - loss: 2.2547 - acc: 0.3074 - val_loss: 3.4611 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "Epoch 00091: val_loss did not improve\n",
      " - 7s - loss: 2.1374 - acc: 0.4168 - val_loss: 3.4347 - val_acc: 0.2333\n",
      "Epoch 92/100\n",
      "Epoch 00092: val_loss did not improve\n",
      " - 9s - loss: 2.2690 - acc: 0.3021 - val_loss: 3.4217 - val_acc: 0.2333\n",
      "Epoch 93/100\n",
      "Epoch 00093: val_loss did not improve\n",
      " - 7s - loss: 2.6950 - acc: 0.2183 - val_loss: 3.4411 - val_acc: 0.2333\n",
      "Epoch 94/100\n",
      "Epoch 00094: val_loss did not improve\n",
      " - 9s - loss: 2.3486 - acc: 0.2812 - val_loss: 3.4667 - val_acc: 0.2333\n",
      "Epoch 95/100\n",
      "Epoch 00095: val_loss did not improve\n",
      " - 6s - loss: 2.2223 - acc: 0.3736 - val_loss: 3.4867 - val_acc: 0.2667\n",
      "Epoch 96/100\n",
      "Epoch 00096: val_loss did not improve\n",
      " - 7s - loss: 2.2237 - acc: 0.3419 - val_loss: 3.5099 - val_acc: 0.2667\n",
      "Epoch 97/100\n",
      "Epoch 00097: val_loss did not improve\n",
      " - 8s - loss: 2.2580 - acc: 0.3021 - val_loss: 3.5265 - val_acc: 0.2667\n",
      "Epoch 98/100\n",
      "Epoch 00098: val_loss did not improve\n",
      " - 7s - loss: 1.9219 - acc: 0.4858 - val_loss: 3.5276 - val_acc: 0.2667\n",
      "Epoch 99/100\n",
      "Epoch 00099: val_loss did not improve\n",
      " - 6s - loss: 1.6784 - acc: 0.4972 - val_loss: 3.5622 - val_acc: 0.3000\n",
      "Epoch 100/100\n",
      "Epoch 00100: val_loss did not improve\n",
      " - 6s - loss: 2.2209 - acc: 0.3649 - val_loss: 3.5595 - val_acc: 0.3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff60c1cbfd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the CNN again\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "#train the model\n",
    "checkpointer = ModelCheckpoint(filepath='augment_model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=x_train.shape[0] \\\n",
    "                   // batch_size, epochs=epochs, verbose=2, callbacks=[checkpointer], \\\n",
    "                   validation_data=(x_valid, y_valid), validation_steps=x_valid.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model with best accuracy\n",
    "model.load_weights('augment_model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy: 0.3499999940395355\n"
     ]
    }
   ],
   "source": [
    "#evaluate and print accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disappointing results:\n",
    "\n",
    "I am guessing that because it is not the same as shifting, flipping vertically/horizontally a picture of a cat or dog, ie. the location of the dot is what ties it to its label, this type of image augmentation has very little benefit.  \n",
    "\n",
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Preprocess Sample Images\n",
    "\n",
    "Before supplying an image to a pre-trained network in Keras, there are some required preprocessing steps.  \n",
    "You will learn more about this in the project; for now, we have implemented this functionality for you in the \n",
    "first code cell of the notebook.  We have imported a very small dataset of 8 images and stored the  preprocessed image input as `img_input`.  Note that the dimensionality of this array is `(8, 224, 224, 3)`.  In this case, each of the 8 images is a 3D tensor, with shape `(224, 224, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#skip this cell since we already have bottleneck features\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "img_paths = glob.glob(\"DataSet/Image/*.png\")\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "# calculate the image input. you will learn more about how this works the project!\n",
    "img_input = preprocess_input(paths_to_tensor(img_paths))\n",
    "\n",
    "print(img_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottleneck Features from Colab VGG16\n",
    "<a id='the_destination'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 3, 3, 512) (100, 3, 3, 512) (120, 3, 3, 512)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Start running from this cell.  Load the bottleneck feature .npy files\"\"\"\n",
    "\n",
    "bottleneck_features_train = np.load('bottleneck_vgg16/bottleneck_train.npy')\n",
    "bottleneck_features_valid = np.load('bottleneck_vgg16/bottleneck_valid.npy')\n",
    "bottleneck_features_test = np.load('bottleneck_vgg16/bottleneck_test.npy')\n",
    "\n",
    "print(bottleneck_features_train.shape, bottleneck_features_valid.shape, bottleneck_features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"skip this cell\n",
    "divide input into train, valid, test\"\"\"\n",
    "train_data = img_input[:100]\n",
    "valid_data = img_input[100:130]\n",
    "test_data = img_input[130:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#run this cell\n",
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip this cell\n",
    "#get bottleneck features and save them\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "bottleneck_train = TemporaryFile()\n",
    "bottleneck_valid = TemporaryFile()\n",
    "bottleneck_test = TemporaryFile()\n",
    "\n",
    "bottleneck_features_train = model.predict(train_data)\n",
    "#np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n",
    "np.save(bottleneck_train, bottleneck_features_train)\n",
    "\n",
    "bottleneck_features_valid = model.predict(valid_data)\n",
    "#np.save(open('bottleneck_features_valid.npy', 'w'), bottleneck_features_valid)\n",
    "np.save(bottleneck_valid, bottleneck_features_valid)\n",
    "\n",
    "#put test_data through base model\n",
    "bottleneck_features_test = model.predict(test_data)\n",
    "np.save(bottleneck_test, bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Model Architecture (Model 1)\n",
    "## Skip this model and go to Model 2\n",
    "\n",
    "Click on the link to go to model 2: [Link to Model 2](#model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_8 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 50)                25650     \n",
      "=================================================================\n",
      "Total params: 25,650\n",
      "Trainable params: 25,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "num_classes = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GlobalAveragePooling2D(input_shape=(7, 7, 512))) #shape of final max pooling layer of VGG-16\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax' ))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      " 32/100 [========>.....................] - ETA: 2s - loss: 6.7852 - acc: 0.0000e+00Epoch 00001: val_loss improved from inf to 4.81184, saving model to detectorvgg16.weights.best.hdf5\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 6.6144 - acc: 0.0000e+00 - val_loss: 4.8118 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 5.8363 - acc: 0.0000e+00Epoch 00002: val_loss improved from 4.81184 to 4.79578, saving model to detectorvgg16.weights.best.hdf5\n",
      "100/100 [==============================] - 0s 597us/step - loss: 5.9788 - acc: 0.0200 - val_loss: 4.7958 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 5.1741 - acc: 0.0000e+00Epoch 00003: val_loss did not improve\n",
      "100/100 [==============================] - 0s 230us/step - loss: 5.6915 - acc: 0.0200 - val_loss: 4.7983 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 5.9817 - acc: 0.0000e+00Epoch 00004: val_loss did not improve\n",
      "100/100 [==============================] - 0s 385us/step - loss: 5.8765 - acc: 0.0200 - val_loss: 4.8077 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 5.3472 - acc: 0.0938Epoch 00005: val_loss did not improve\n",
      "100/100 [==============================] - 0s 381us/step - loss: 5.1698 - acc: 0.0700 - val_loss: 4.8354 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.6521 - acc: 0.0938Epoch 00006: val_loss did not improve\n",
      "100/100 [==============================] - 0s 448us/step - loss: 4.9430 - acc: 0.0600 - val_loss: 4.8720 - val_acc: 0.0333\n",
      "Epoch 7/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 5.3612 - acc: 0.0000e+00Epoch 00007: val_loss did not improve\n",
      "100/100 [==============================] - 0s 417us/step - loss: 5.0036 - acc: 0.0600 - val_loss: 4.9117 - val_acc: 0.0667\n",
      "Epoch 8/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.8581 - acc: 0.0000e+00Epoch 00008: val_loss did not improve\n",
      "100/100 [==============================] - 0s 292us/step - loss: 4.7010 - acc: 0.0300 - val_loss: 4.9589 - val_acc: 0.0667\n",
      "Epoch 9/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.7268 - acc: 0.0312Epoch 00009: val_loss did not improve\n",
      "100/100 [==============================] - 0s 267us/step - loss: 4.8484 - acc: 0.0500 - val_loss: 5.0161 - val_acc: 0.0333\n",
      "Epoch 10/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 5.0030 - acc: 0.0312Epoch 00010: val_loss did not improve\n",
      "100/100 [==============================] - 0s 287us/step - loss: 4.8545 - acc: 0.0100 - val_loss: 5.0607 - val_acc: 0.0667\n",
      "Epoch 11/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.0309 - acc: 0.0312Epoch 00011: val_loss did not improve\n",
      "100/100 [==============================] - 0s 296us/step - loss: 4.6234 - acc: 0.0100 - val_loss: 5.1036 - val_acc: 0.0667\n",
      "Epoch 12/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.0063 - acc: 0.0938Epoch 00012: val_loss did not improve\n",
      "100/100 [==============================] - 0s 299us/step - loss: 4.5576 - acc: 0.0500 - val_loss: 5.1216 - val_acc: 0.0667\n",
      "Epoch 13/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.5526 - acc: 0.0938Epoch 00013: val_loss did not improve\n",
      "100/100 [==============================] - 0s 283us/step - loss: 4.5290 - acc: 0.0600 - val_loss: 5.1386 - val_acc: 0.0667\n",
      "Epoch 14/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.6970 - acc: 0.0000e+00Epoch 00014: val_loss did not improve\n",
      "100/100 [==============================] - 0s 234us/step - loss: 4.3966 - acc: 0.0200 - val_loss: 5.1636 - val_acc: 0.0333\n",
      "Epoch 15/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.9519 - acc: 0.1250Epoch 00015: val_loss did not improve\n",
      "100/100 [==============================] - 0s 261us/step - loss: 4.2185 - acc: 0.0700 - val_loss: 5.2012 - val_acc: 0.0333\n",
      "Epoch 16/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.6392 - acc: 0.0312Epoch 00016: val_loss did not improve\n",
      "100/100 [==============================] - 0s 296us/step - loss: 4.4772 - acc: 0.0200 - val_loss: 5.2376 - val_acc: 0.0333\n",
      "Epoch 17/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 5.3000 - acc: 0.0625Epoch 00017: val_loss did not improve\n",
      "100/100 [==============================] - 0s 259us/step - loss: 4.6691 - acc: 0.0600 - val_loss: 5.2757 - val_acc: 0.0333\n",
      "Epoch 18/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.5029 - acc: 0.0000e+00Epoch 00018: val_loss did not improve\n",
      "100/100 [==============================] - 0s 275us/step - loss: 4.3327 - acc: 0.0300 - val_loss: 5.2987 - val_acc: 0.0333\n",
      "Epoch 19/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.2203 - acc: 0.0938Epoch 00019: val_loss did not improve\n",
      "100/100 [==============================] - 0s 259us/step - loss: 4.5276 - acc: 0.0400 - val_loss: 5.3198 - val_acc: 0.0333\n",
      "Epoch 20/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.3096 - acc: 0.0938Epoch 00020: val_loss did not improve\n",
      "100/100 [==============================] - 0s 283us/step - loss: 4.0468 - acc: 0.0600 - val_loss: 5.3299 - val_acc: 0.0333\n",
      "Epoch 21/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.8125 - acc: 0.0312Epoch 00021: val_loss did not improve\n",
      "100/100 [==============================] - 0s 278us/step - loss: 4.4797 - acc: 0.0600 - val_loss: 5.3380 - val_acc: 0.0333\n",
      "Epoch 22/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.2845 - acc: 0.0938Epoch 00022: val_loss did not improve\n",
      "100/100 [==============================] - 0s 223us/step - loss: 4.2397 - acc: 0.1200 - val_loss: 5.3413 - val_acc: 0.0667\n",
      "Epoch 23/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.7510 - acc: 0.0938Epoch 00023: val_loss did not improve\n",
      "100/100 [==============================] - 0s 375us/step - loss: 3.9652 - acc: 0.0600 - val_loss: 5.3485 - val_acc: 0.0667\n",
      "Epoch 24/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.0772 - acc: 0.0312Epoch 00024: val_loss did not improve\n",
      "100/100 [==============================] - 0s 231us/step - loss: 4.0110 - acc: 0.0500 - val_loss: 5.3656 - val_acc: 0.0667\n",
      "Epoch 25/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.8844 - acc: 0.0625Epoch 00025: val_loss did not improve\n",
      "100/100 [==============================] - 0s 245us/step - loss: 3.9176 - acc: 0.0600 - val_loss: 5.3919 - val_acc: 0.0667\n",
      "Epoch 26/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.0517 - acc: 0.0625Epoch 00026: val_loss did not improve\n",
      "100/100 [==============================] - 0s 319us/step - loss: 4.0460 - acc: 0.0900 - val_loss: 5.4156 - val_acc: 0.0333\n",
      "Epoch 27/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.1641 - acc: 0.0312Epoch 00027: val_loss did not improve\n",
      "100/100 [==============================] - 0s 310us/step - loss: 4.0240 - acc: 0.0900 - val_loss: 5.4288 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.0720 - acc: 0.0000e+00Epoch 00028: val_loss did not improve\n",
      "100/100 [==============================] - 0s 330us/step - loss: 4.2100 - acc: 0.0400 - val_loss: 5.4402 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.0812 - acc: 0.0000e+00Epoch 00029: val_loss did not improve\n",
      "100/100 [==============================] - 0s 268us/step - loss: 4.0254 - acc: 0.0100 - val_loss: 5.4563 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.7819 - acc: 0.0625Epoch 00030: val_loss did not improve\n",
      "100/100 [==============================] - 0s 243us/step - loss: 4.0164 - acc: 0.0600 - val_loss: 5.4748 - val_acc: 0.0333\n",
      "Epoch 31/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.7529 - acc: 0.0625Epoch 00031: val_loss did not improve\n",
      "100/100 [==============================] - 0s 287us/step - loss: 3.9157 - acc: 0.0500 - val_loss: 5.4846 - val_acc: 0.0333\n",
      "Epoch 32/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.9166 - acc: 0.0938Epoch 00032: val_loss did not improve\n",
      "100/100 [==============================] - 0s 305us/step - loss: 3.9170 - acc: 0.0900 - val_loss: 5.4896 - val_acc: 0.0333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 4.0127 - acc: 0.0000e+00Epoch 00033: val_loss did not improve\n",
      "100/100 [==============================] - 0s 256us/step - loss: 3.9336 - acc: 0.0300 - val_loss: 5.4949 - val_acc: 0.0333\n",
      "Epoch 34/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.5038 - acc: 0.1875Epoch 00034: val_loss did not improve\n",
      "100/100 [==============================] - 0s 336us/step - loss: 3.7109 - acc: 0.1400 - val_loss: 5.5075 - val_acc: 0.0667\n",
      "Epoch 35/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.7551 - acc: 0.0938Epoch 00035: val_loss did not improve\n",
      "100/100 [==============================] - 0s 228us/step - loss: 3.7258 - acc: 0.0800 - val_loss: 5.5276 - val_acc: 0.0667\n",
      "Epoch 36/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.8486 - acc: 0.0625Epoch 00036: val_loss did not improve\n",
      "100/100 [==============================] - 0s 308us/step - loss: 3.7866 - acc: 0.1000 - val_loss: 5.5484 - val_acc: 0.0667\n",
      "Epoch 37/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.7383 - acc: 0.0625Epoch 00037: val_loss did not improve\n",
      "100/100 [==============================] - 0s 259us/step - loss: 3.5645 - acc: 0.1000 - val_loss: 5.5748 - val_acc: 0.0333\n",
      "Epoch 38/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.3498 - acc: 0.0312Epoch 00038: val_loss did not improve\n",
      "100/100 [==============================] - 0s 261us/step - loss: 3.7668 - acc: 0.0400 - val_loss: 5.6105 - val_acc: 0.0333\n",
      "Epoch 39/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.5144 - acc: 0.1250Epoch 00039: val_loss did not improve\n",
      "100/100 [==============================] - 0s 236us/step - loss: 3.4867 - acc: 0.1100 - val_loss: 5.6278 - val_acc: 0.0333\n",
      "Epoch 40/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.9655 - acc: 0.0938Epoch 00040: val_loss did not improve\n",
      "100/100 [==============================] - 0s 272us/step - loss: 3.6294 - acc: 0.1200 - val_loss: 5.6261 - val_acc: 0.0333\n",
      "Epoch 41/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.4535 - acc: 0.0000e+00Epoch 00041: val_loss did not improve\n",
      "100/100 [==============================] - 0s 242us/step - loss: 3.6996 - acc: 0.0600 - val_loss: 5.6177 - val_acc: 0.0333\n",
      "Epoch 42/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.5338 - acc: 0.1250Epoch 00042: val_loss did not improve\n",
      "100/100 [==============================] - 0s 263us/step - loss: 3.5123 - acc: 0.1000 - val_loss: 5.6134 - val_acc: 0.0333\n",
      "Epoch 43/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.5363 - acc: 0.0000e+00Epoch 00043: val_loss did not improve\n",
      "100/100 [==============================] - 0s 252us/step - loss: 3.3801 - acc: 0.1300 - val_loss: 5.6101 - val_acc: 0.0667\n",
      "Epoch 44/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.7460 - acc: 0.0625Epoch 00044: val_loss did not improve\n",
      "100/100 [==============================] - 0s 240us/step - loss: 3.5256 - acc: 0.0800 - val_loss: 5.6177 - val_acc: 0.0667\n",
      "Epoch 45/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.4124 - acc: 0.1250Epoch 00045: val_loss did not improve\n",
      "100/100 [==============================] - 0s 227us/step - loss: 3.5842 - acc: 0.0900 - val_loss: 5.6365 - val_acc: 0.0667\n",
      "Epoch 46/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.4372 - acc: 0.0625Epoch 00046: val_loss did not improve\n",
      "100/100 [==============================] - 0s 290us/step - loss: 3.4054 - acc: 0.1000 - val_loss: 5.6526 - val_acc: 0.0667\n",
      "Epoch 47/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.7676 - acc: 0.0000e+00Epoch 00047: val_loss did not improve\n",
      "100/100 [==============================] - 0s 278us/step - loss: 3.6722 - acc: 0.0700 - val_loss: 5.6758 - val_acc: 0.0667\n",
      "Epoch 48/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.3558 - acc: 0.0625Epoch 00048: val_loss did not improve\n",
      "100/100 [==============================] - 0s 246us/step - loss: 3.3683 - acc: 0.1100 - val_loss: 5.6877 - val_acc: 0.0667\n",
      "Epoch 49/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.8081 - acc: 0.0000e+00Epoch 00049: val_loss did not improve\n",
      "100/100 [==============================] - 0s 238us/step - loss: 3.6729 - acc: 0.0900 - val_loss: 5.7015 - val_acc: 0.0667\n",
      "Epoch 50/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.4121 - acc: 0.1562Epoch 00050: val_loss did not improve\n",
      "100/100 [==============================] - 0s 248us/step - loss: 3.4853 - acc: 0.1200 - val_loss: 5.7062 - val_acc: 0.0667\n",
      "Epoch 51/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.2129 - acc: 0.2188Epoch 00051: val_loss did not improve\n",
      "100/100 [==============================] - 0s 239us/step - loss: 3.4185 - acc: 0.1300 - val_loss: 5.7246 - val_acc: 0.0667\n",
      "Epoch 52/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.4861 - acc: 0.0938Epoch 00052: val_loss did not improve\n",
      "100/100 [==============================] - 0s 237us/step - loss: 3.4167 - acc: 0.0700 - val_loss: 5.7577 - val_acc: 0.0333\n",
      "Epoch 53/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9130 - acc: 0.1562Epoch 00053: val_loss did not improve\n",
      "100/100 [==============================] - 0s 245us/step - loss: 3.1858 - acc: 0.1700 - val_loss: 5.7902 - val_acc: 0.0333\n",
      "Epoch 54/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.7195 - acc: 0.0938Epoch 00054: val_loss did not improve\n",
      "100/100 [==============================] - 0s 228us/step - loss: 3.5215 - acc: 0.0800 - val_loss: 5.8207 - val_acc: 0.0333\n",
      "Epoch 55/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.5565 - acc: 0.0938Epoch 00055: val_loss did not improve\n",
      "100/100 [==============================] - 0s 245us/step - loss: 3.5699 - acc: 0.0500 - val_loss: 5.8444 - val_acc: 0.0333\n",
      "Epoch 56/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.3174 - acc: 0.1250Epoch 00056: val_loss did not improve\n",
      "100/100 [==============================] - 0s 238us/step - loss: 3.3645 - acc: 0.1100 - val_loss: 5.8751 - val_acc: 0.0333\n",
      "Epoch 57/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.0738 - acc: 0.1875Epoch 00057: val_loss did not improve\n",
      "100/100 [==============================] - 0s 249us/step - loss: 3.4248 - acc: 0.1200 - val_loss: 5.9116 - val_acc: 0.0333\n",
      "Epoch 58/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.4544 - acc: 0.0312Epoch 00058: val_loss did not improve\n",
      "100/100 [==============================] - 0s 256us/step - loss: 3.2736 - acc: 0.0800 - val_loss: 5.9354 - val_acc: 0.0333\n",
      "Epoch 59/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.0517 - acc: 0.0938Epoch 00059: val_loss did not improve\n",
      "100/100 [==============================] - 0s 251us/step - loss: 3.3151 - acc: 0.0800 - val_loss: 5.9496 - val_acc: 0.0333\n",
      "Epoch 60/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.1728 - acc: 0.1562Epoch 00060: val_loss did not improve\n",
      "100/100 [==============================] - 0s 275us/step - loss: 3.2201 - acc: 0.1200 - val_loss: 5.9670 - val_acc: 0.0333\n",
      "Epoch 61/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.0121 - acc: 0.1562Epoch 00061: val_loss did not improve\n",
      "100/100 [==============================] - 0s 263us/step - loss: 3.3677 - acc: 0.1100 - val_loss: 5.9805 - val_acc: 0.0333\n",
      "Epoch 62/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.2344 - acc: 0.1250Epoch 00062: val_loss did not improve\n",
      "100/100 [==============================] - 0s 245us/step - loss: 3.1318 - acc: 0.1300 - val_loss: 5.9879 - val_acc: 0.0333\n",
      "Epoch 63/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.3868 - acc: 0.1250Epoch 00063: val_loss did not improve\n",
      "100/100 [==============================] - 0s 228us/step - loss: 3.2474 - acc: 0.1200 - val_loss: 5.9867 - val_acc: 0.0333\n",
      "Epoch 64/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9338 - acc: 0.1875Epoch 00064: val_loss did not improve\n",
      "100/100 [==============================] - 0s 254us/step - loss: 3.0313 - acc: 0.1600 - val_loss: 5.9901 - val_acc: 0.0667\n",
      "Epoch 65/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.2638 - acc: 0.0312Epoch 00065: val_loss did not improve\n",
      "100/100 [==============================] - 0s 250us/step - loss: 3.2411 - acc: 0.1000 - val_loss: 6.0031 - val_acc: 0.0333\n",
      "Epoch 66/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.1367 - acc: 0.0312Epoch 00066: val_loss did not improve\n",
      "100/100 [==============================] - 0s 247us/step - loss: 3.2023 - acc: 0.0800 - val_loss: 6.0116 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9265 - acc: 0.1875Epoch 00067: val_loss did not improve\n",
      "100/100 [==============================] - 0s 280us/step - loss: 3.1959 - acc: 0.1400 - val_loss: 6.0155 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.2719 - acc: 0.1875Epoch 00068: val_loss did not improve\n",
      "100/100 [==============================] - 0s 232us/step - loss: 3.1189 - acc: 0.1700 - val_loss: 6.0130 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.3953 - acc: 0.0938Epoch 00069: val_loss did not improve\n",
      "100/100 [==============================] - 0s 236us/step - loss: 3.2268 - acc: 0.1100 - val_loss: 6.0070 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.3265 - acc: 0.1250Epoch 00070: val_loss did not improve\n",
      "100/100 [==============================] - 0s 241us/step - loss: 3.2321 - acc: 0.1300 - val_loss: 6.0065 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.0363 - acc: 0.0938Epoch 00071: val_loss did not improve\n",
      "100/100 [==============================] - 0s 228us/step - loss: 3.2898 - acc: 0.0900 - val_loss: 6.0168 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.7752 - acc: 0.2188Epoch 00072: val_loss did not improve\n",
      "100/100 [==============================] - 0s 250us/step - loss: 2.9883 - acc: 0.1500 - val_loss: 6.0281 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.0966 - acc: 0.1562Epoch 00073: val_loss did not improve\n",
      "100/100 [==============================] - 0s 317us/step - loss: 3.0911 - acc: 0.1500 - val_loss: 6.0360 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.7663 - acc: 0.2500Epoch 00074: val_loss did not improve\n",
      "100/100 [==============================] - 0s 297us/step - loss: 2.9791 - acc: 0.2000 - val_loss: 6.0270 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.1475 - acc: 0.1250Epoch 00075: val_loss did not improve\n",
      "100/100 [==============================] - 0s 343us/step - loss: 3.0162 - acc: 0.1500 - val_loss: 6.0103 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.2606 - acc: 0.0938Epoch 00076: val_loss did not improve\n",
      "100/100 [==============================] - 0s 298us/step - loss: 2.9366 - acc: 0.1900 - val_loss: 6.0047 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.8930 - acc: 0.2188Epoch 00077: val_loss did not improve\n",
      "100/100 [==============================] - 0s 320us/step - loss: 2.8861 - acc: 0.1600 - val_loss: 6.0083 - val_acc: 0.0333\n",
      "Epoch 78/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.8358 - acc: 0.1562Epoch 00078: val_loss did not improve\n",
      "100/100 [==============================] - 0s 318us/step - loss: 2.9745 - acc: 0.1400 - val_loss: 6.0163 - val_acc: 0.0333\n",
      "Epoch 79/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9641 - acc: 0.2188Epoch 00079: val_loss did not improve\n",
      "100/100 [==============================] - 0s 368us/step - loss: 3.0023 - acc: 0.1700 - val_loss: 6.0299 - val_acc: 0.0333\n",
      "Epoch 80/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.0637 - acc: 0.0938Epoch 00080: val_loss did not improve\n",
      "100/100 [==============================] - 0s 299us/step - loss: 3.0097 - acc: 0.1400 - val_loss: 6.0503 - val_acc: 0.0333\n",
      "Epoch 81/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9218 - acc: 0.1875Epoch 00081: val_loss did not improve\n",
      "100/100 [==============================] - 0s 277us/step - loss: 3.0633 - acc: 0.1700 - val_loss: 6.0658 - val_acc: 0.0333\n",
      "Epoch 82/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9675 - acc: 0.2188Epoch 00082: val_loss did not improve\n",
      "100/100 [==============================] - 0s 281us/step - loss: 2.8989 - acc: 0.1700 - val_loss: 6.0784 - val_acc: 0.0333\n",
      "Epoch 83/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9020 - acc: 0.1562Epoch 00083: val_loss did not improve\n",
      "100/100 [==============================] - 0s 313us/step - loss: 3.0701 - acc: 0.1700 - val_loss: 6.0945 - val_acc: 0.0333\n",
      "Epoch 84/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.1912 - acc: 0.0625Epoch 00084: val_loss did not improve\n",
      "100/100 [==============================] - 0s 353us/step - loss: 3.0448 - acc: 0.1600 - val_loss: 6.1184 - val_acc: 0.0333\n",
      "Epoch 85/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.0620 - acc: 0.1250Epoch 00085: val_loss did not improve\n",
      "100/100 [==============================] - 0s 309us/step - loss: 2.9414 - acc: 0.1500 - val_loss: 6.1470 - val_acc: 0.0333\n",
      "Epoch 86/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.7396 - acc: 0.3125Epoch 00086: val_loss did not improve\n",
      "100/100 [==============================] - 0s 288us/step - loss: 2.8830 - acc: 0.2100 - val_loss: 6.1763 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.6953 - acc: 0.1250Epoch 00087: val_loss did not improve\n",
      "100/100 [==============================] - 0s 344us/step - loss: 2.8393 - acc: 0.1600 - val_loss: 6.2069 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9219 - acc: 0.2188Epoch 00088: val_loss did not improve\n",
      "100/100 [==============================] - 0s 241us/step - loss: 2.9447 - acc: 0.1500 - val_loss: 6.2325 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.8116 - acc: 0.1875Epoch 00089: val_loss did not improve\n",
      "100/100 [==============================] - 0s 372us/step - loss: 2.9666 - acc: 0.1100 - val_loss: 6.2498 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.8740 - acc: 0.3125Epoch 00090: val_loss did not improve\n",
      "100/100 [==============================] - 0s 390us/step - loss: 2.8322 - acc: 0.2400 - val_loss: 6.2631 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.7475 - acc: 0.2812Epoch 00091: val_loss did not improve\n",
      "100/100 [==============================] - 0s 233us/step - loss: 2.9517 - acc: 0.1900 - val_loss: 6.2675 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.7290 - acc: 0.2500Epoch 00092: val_loss did not improve\n",
      "100/100 [==============================] - 0s 411us/step - loss: 2.6839 - acc: 0.2600 - val_loss: 6.2665 - val_acc: 0.0333\n",
      "Epoch 93/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.7219 - acc: 0.1875Epoch 00093: val_loss did not improve\n",
      "100/100 [==============================] - 0s 290us/step - loss: 2.7563 - acc: 0.1900 - val_loss: 6.2650 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9409 - acc: 0.0938Epoch 00094: val_loss did not improve\n",
      "100/100 [==============================] - 0s 295us/step - loss: 2.8966 - acc: 0.1700 - val_loss: 6.2531 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.6038 - acc: 0.2500Epoch 00095: val_loss did not improve\n",
      "100/100 [==============================] - 0s 286us/step - loss: 2.8203 - acc: 0.2000 - val_loss: 6.2289 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9140 - acc: 0.1250Epoch 00096: val_loss did not improve\n",
      "100/100 [==============================] - 0s 322us/step - loss: 2.9150 - acc: 0.1600 - val_loss: 6.2164 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.7825 - acc: 0.1875Epoch 00097: val_loss did not improve\n",
      "100/100 [==============================] - 0s 317us/step - loss: 2.8227 - acc: 0.1800 - val_loss: 6.2105 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 3.1612 - acc: 0.0938Epoch 00098: val_loss did not improve\n",
      "100/100 [==============================] - 0s 344us/step - loss: 2.8515 - acc: 0.2000 - val_loss: 6.2011 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.9479 - acc: 0.1250Epoch 00099: val_loss did not improve\n",
      "100/100 [==============================] - 0s 241us/step - loss: 2.7650 - acc: 0.2000 - val_loss: 6.1996 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      " 32/100 [========>.....................] - ETA: 0s - loss: 2.5652 - acc: 0.4062Epoch 00100: val_loss did not improve\n",
      "100/100 [==============================] - 0s 260us/step - loss: 2.7948 - acc: 0.2400 - val_loss: 6.1969 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5a419d710>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='detectorvgg16.weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(bottleneck_features_train, y_train, batch_size = 32, epochs=100, validation_data=(bottleneck_features_valid, y_valid), \\\n",
    "         callbacks=[checkpointer], verbose=1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2\n",
    "\n",
    "<a id='model2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                12850     \n",
      "=================================================================\n",
      "Total params: 1,193,778\n",
      "Trainable params: 1,193,266\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#run this cell\n",
    "from keras.layers import Dense, Flatten, Activation, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(3, 3, 512))) #for bottleneck this is (3,3,512)\n",
    "#model2.add(GlobalAveragePooling2D(input_shape=(7, 7, 512)))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(256))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.8))\n",
    "model2.add(Dense(50, activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 380 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 5.2666 - acc: 0.0469Epoch 00001: val_loss improved from inf to 4.31820, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 4ms/step - loss: 5.1406 - acc: 0.0474 - val_loss: 4.3182 - val_acc: 0.1100\n",
      "Epoch 2/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 3.8909 - acc: 0.1215Epoch 00002: val_loss improved from 4.31820 to 2.46264, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 3.7771 - acc: 0.1447 - val_loss: 2.4626 - val_acc: 0.4700\n",
      "Epoch 3/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 3.1289 - acc: 0.2443Epoch 00003: val_loss improved from 2.46264 to 2.00314, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 3.1422 - acc: 0.2447 - val_loss: 2.0031 - val_acc: 0.5600\n",
      "Epoch 4/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 2.7053 - acc: 0.3466Epoch 00004: val_loss improved from 2.00314 to 1.57930, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 2.7287 - acc: 0.3368 - val_loss: 1.5793 - val_acc: 0.6300\n",
      "Epoch 5/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 2.2283 - acc: 0.4290Epoch 00005: val_loss improved from 1.57930 to 1.32919, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 2.2739 - acc: 0.4237 - val_loss: 1.3292 - val_acc: 0.6600\n",
      "Epoch 6/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 2.1459 - acc: 0.3854Epoch 00006: val_loss improved from 1.32919 to 1.14700, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 2.1818 - acc: 0.4079 - val_loss: 1.1470 - val_acc: 0.6900\n",
      "Epoch 7/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 2.0277 - acc: 0.4531Epoch 00007: val_loss improved from 1.14700 to 1.07209, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 1.9949 - acc: 0.4474 - val_loss: 1.0721 - val_acc: 0.6900\n",
      "Epoch 8/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 1.7579 - acc: 0.5114Epoch 00008: val_loss improved from 1.07209 to 1.00810, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 1.7252 - acc: 0.5184 - val_loss: 1.0081 - val_acc: 0.7200\n",
      "Epoch 9/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 1.6165 - acc: 0.5085Epoch 00009: val_loss improved from 1.00810 to 0.92548, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 1.5949 - acc: 0.5158 - val_loss: 0.9255 - val_acc: 0.7400\n",
      "Epoch 10/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 1.5662 - acc: 0.5625Epoch 00010: val_loss improved from 0.92548 to 0.85222, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 1.5740 - acc: 0.5526 - val_loss: 0.8522 - val_acc: 0.7600\n",
      "Epoch 11/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 1.4970 - acc: 0.5682Epoch 00011: val_loss improved from 0.85222 to 0.80015, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 1.5005 - acc: 0.5737 - val_loss: 0.8001 - val_acc: 0.7800\n",
      "Epoch 12/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 1.4593 - acc: 0.6181Epoch 00012: val_loss improved from 0.80015 to 0.75091, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 1.4119 - acc: 0.6263 - val_loss: 0.7509 - val_acc: 0.7900\n",
      "Epoch 13/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 1.3428 - acc: 0.6080Epoch 00013: val_loss improved from 0.75091 to 0.71673, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 1.3358 - acc: 0.6105 - val_loss: 0.7167 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 1.3578 - acc: 0.6146Epoch 00014: val_loss improved from 0.71673 to 0.71353, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 1.3334 - acc: 0.6237 - val_loss: 0.7135 - val_acc: 0.8100\n",
      "Epoch 15/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 1.3171 - acc: 0.6188Epoch 00015: val_loss improved from 0.71353 to 0.70484, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 1.3175 - acc: 0.6289 - val_loss: 0.7048 - val_acc: 0.8200\n",
      "Epoch 16/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 1.1013 - acc: 0.6619Epoch 00016: val_loss improved from 0.70484 to 0.68177, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 1.0883 - acc: 0.6658 - val_loss: 0.6818 - val_acc: 0.8100\n",
      "Epoch 17/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 1.2143 - acc: 0.6111Epoch 00017: val_loss improved from 0.68177 to 0.64500, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 1.1763 - acc: 0.6447 - val_loss: 0.6450 - val_acc: 0.8200\n",
      "Epoch 18/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 1.1601 - acc: 0.6528Epoch 00018: val_loss improved from 0.64500 to 0.61481, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 1.1004 - acc: 0.6842 - val_loss: 0.6148 - val_acc: 0.8500\n",
      "Epoch 19/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 1.0865 - acc: 0.6875Epoch 00019: val_loss improved from 0.61481 to 0.57527, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 1.0445 - acc: 0.7000 - val_loss: 0.5753 - val_acc: 0.8700\n",
      "Epoch 20/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.9753 - acc: 0.7219Epoch 00020: val_loss improved from 0.57527 to 0.56842, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.9862 - acc: 0.7105 - val_loss: 0.5684 - val_acc: 0.8600\n",
      "Epoch 21/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.9506 - acc: 0.7118Epoch 00021: val_loss did not improve\n",
      "380/380 [==============================] - 0s 793us/step - loss: 0.9149 - acc: 0.7237 - val_loss: 0.5794 - val_acc: 0.8600\n",
      "Epoch 22/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 1.0464 - acc: 0.7094Epoch 00022: val_loss improved from 0.56842 to 0.55081, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 1.0754 - acc: 0.6868 - val_loss: 0.5508 - val_acc: 0.8700\n",
      "Epoch 23/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.8914 - acc: 0.7535Epoch 00023: val_loss improved from 0.55081 to 0.53689, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.9257 - acc: 0.7421 - val_loss: 0.5369 - val_acc: 0.8800\n",
      "Epoch 24/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.8623 - acc: 0.7281Epoch 00024: val_loss improved from 0.53689 to 0.51763, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.8487 - acc: 0.7500 - val_loss: 0.5176 - val_acc: 0.8800\n",
      "Epoch 25/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.8854 - acc: 0.7344Epoch 00025: val_loss improved from 0.51763 to 0.49459, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 0.9208 - acc: 0.7158 - val_loss: 0.4946 - val_acc: 0.8800\n",
      "Epoch 26/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.7893 - acc: 0.7743Epoch 00026: val_loss improved from 0.49459 to 0.47487, saving model to model2.detectorvgg16.weights.best.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 1s 1ms/step - loss: 0.8577 - acc: 0.7500 - val_loss: 0.4749 - val_acc: 0.8800\n",
      "Epoch 27/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.8211 - acc: 0.7594Epoch 00027: val_loss improved from 0.47487 to 0.44624, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.8228 - acc: 0.7605 - val_loss: 0.4462 - val_acc: 0.8800\n",
      "Epoch 28/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.8117 - acc: 0.7569Epoch 00028: val_loss improved from 0.44624 to 0.44011, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.8068 - acc: 0.7474 - val_loss: 0.4401 - val_acc: 0.8900\n",
      "Epoch 29/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.8535 - acc: 0.7375Epoch 00029: val_loss improved from 0.44011 to 0.42295, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 0.8200 - acc: 0.7526 - val_loss: 0.4229 - val_acc: 0.8900\n",
      "Epoch 30/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.7629 - acc: 0.7812Epoch 00030: val_loss improved from 0.42295 to 0.42112, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.8162 - acc: 0.7368 - val_loss: 0.4211 - val_acc: 0.9000\n",
      "Epoch 31/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.7956 - acc: 0.7604Epoch 00031: val_loss improved from 0.42112 to 0.41997, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 0.7616 - acc: 0.7763 - val_loss: 0.4200 - val_acc: 0.9000\n",
      "Epoch 32/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.8270 - acc: 0.7569Epoch 00032: val_loss improved from 0.41997 to 0.40855, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.8261 - acc: 0.7474 - val_loss: 0.4085 - val_acc: 0.9000\n",
      "Epoch 33/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.7499 - acc: 0.7465Epoch 00033: val_loss improved from 0.40855 to 0.40698, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.7648 - acc: 0.7447 - val_loss: 0.4070 - val_acc: 0.9100\n",
      "Epoch 34/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.7056 - acc: 0.7955Epoch 00034: val_loss improved from 0.40698 to 0.38679, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.7187 - acc: 0.7974 - val_loss: 0.3868 - val_acc: 0.9100\n",
      "Epoch 35/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.6677 - acc: 0.7906Epoch 00035: val_loss improved from 0.38679 to 0.37468, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.6839 - acc: 0.7895 - val_loss: 0.3747 - val_acc: 0.9100\n",
      "Epoch 36/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.6814 - acc: 0.8000Epoch 00036: val_loss improved from 0.37468 to 0.36719, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.7030 - acc: 0.7895 - val_loss: 0.3672 - val_acc: 0.8900\n",
      "Epoch 37/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.6114 - acc: 0.8125Epoch 00037: val_loss improved from 0.36719 to 0.34113, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.6414 - acc: 0.8026 - val_loss: 0.3411 - val_acc: 0.9200\n",
      "Epoch 38/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.5580 - acc: 0.8368Epoch 00038: val_loss improved from 0.34113 to 0.32088, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.5948 - acc: 0.8132 - val_loss: 0.3209 - val_acc: 0.9200\n",
      "Epoch 39/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.6142 - acc: 0.7969Epoch 00039: val_loss improved from 0.32088 to 0.31757, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 0.5999 - acc: 0.8026 - val_loss: 0.3176 - val_acc: 0.9200\n",
      "Epoch 40/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.7412 - acc: 0.7585Epoch 00040: val_loss did not improve\n",
      "380/380 [==============================] - 0s 851us/step - loss: 0.7180 - acc: 0.7684 - val_loss: 0.3383 - val_acc: 0.9100\n",
      "Epoch 41/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.6390 - acc: 0.8011Epoch 00041: val_loss did not improve\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.6335 - acc: 0.7974 - val_loss: 0.3467 - val_acc: 0.9200\n",
      "Epoch 42/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.5742 - acc: 0.8090Epoch 00042: val_loss did not improve\n",
      "380/380 [==============================] - 0s 777us/step - loss: 0.5700 - acc: 0.8132 - val_loss: 0.3469 - val_acc: 0.8800\n",
      "Epoch 43/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.5895 - acc: 0.8264Epoch 00043: val_loss did not improve\n",
      "380/380 [==============================] - 0s 788us/step - loss: 0.5581 - acc: 0.8368 - val_loss: 0.3404 - val_acc: 0.9000\n",
      "Epoch 44/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.5821 - acc: 0.8210Epoch 00044: val_loss did not improve\n",
      "380/380 [==============================] - 0s 960us/step - loss: 0.5813 - acc: 0.8211 - val_loss: 0.3227 - val_acc: 0.9200\n",
      "Epoch 45/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.5657 - acc: 0.8352Epoch 00045: val_loss improved from 0.31757 to 0.31047, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5634 - acc: 0.8342 - val_loss: 0.3105 - val_acc: 0.8900\n",
      "Epoch 46/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.5257 - acc: 0.8625Epoch 00046: val_loss improved from 0.31047 to 0.29214, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5227 - acc: 0.8526 - val_loss: 0.2921 - val_acc: 0.9100\n",
      "Epoch 47/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.5494 - acc: 0.8125Epoch 00047: val_loss improved from 0.29214 to 0.28201, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.5762 - acc: 0.8026 - val_loss: 0.2820 - val_acc: 0.9200\n",
      "Epoch 48/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.5558 - acc: 0.8063Epoch 00048: val_loss improved from 0.28201 to 0.27843, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 3ms/step - loss: 0.5499 - acc: 0.8105 - val_loss: 0.2784 - val_acc: 0.9200\n",
      "Epoch 49/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4749 - acc: 0.8608Epoch 00049: val_loss improved from 0.27843 to 0.27055, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.4952 - acc: 0.8605 - val_loss: 0.2705 - val_acc: 0.9100\n",
      "Epoch 50/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.5571 - acc: 0.8239Epoch 00050: val_loss improved from 0.27055 to 0.24803, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.5574 - acc: 0.8211 - val_loss: 0.2480 - val_acc: 0.9200\n",
      "Epoch 51/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.5767 - acc: 0.8210Epoch 00051: val_loss improved from 0.24803 to 0.24394, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.5642 - acc: 0.8263 - val_loss: 0.2439 - val_acc: 0.9200\n",
      "Epoch 52/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4952 - acc: 0.8523Epoch 00052: val_loss improved from 0.24394 to 0.24052, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.4916 - acc: 0.8553 - val_loss: 0.2405 - val_acc: 0.9300\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/380 [========================>.....] - ETA: 0s - loss: 0.4589 - acc: 0.8469Epoch 00053: val_loss did not improve\n",
      "380/380 [==============================] - 0s 821us/step - loss: 0.4482 - acc: 0.8474 - val_loss: 0.2488 - val_acc: 0.9200\n",
      "Epoch 54/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.5472 - acc: 0.8000Epoch 00054: val_loss did not improve\n",
      "380/380 [==============================] - 0s 923us/step - loss: 0.5289 - acc: 0.8053 - val_loss: 0.2458 - val_acc: 0.9200\n",
      "Epoch 55/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.5093 - acc: 0.8210Epoch 00055: val_loss improved from 0.24052 to 0.23866, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 0.5013 - acc: 0.8263 - val_loss: 0.2387 - val_acc: 0.9200\n",
      "Epoch 56/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4789 - acc: 0.8523Epoch 00056: val_loss did not improve\n",
      "380/380 [==============================] - 0s 800us/step - loss: 0.4833 - acc: 0.8447 - val_loss: 0.2431 - val_acc: 0.9200\n",
      "Epoch 57/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.4649 - acc: 0.8403Epoch 00057: val_loss did not improve\n",
      "380/380 [==============================] - 0s 779us/step - loss: 0.5014 - acc: 0.8263 - val_loss: 0.2433 - val_acc: 0.9400\n",
      "Epoch 58/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.4635 - acc: 0.8531Epoch 00058: val_loss improved from 0.23866 to 0.23750, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.4710 - acc: 0.8553 - val_loss: 0.2375 - val_acc: 0.9300\n",
      "Epoch 59/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4429 - acc: 0.8523Epoch 00059: val_loss improved from 0.23750 to 0.22564, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 0.4332 - acc: 0.8605 - val_loss: 0.2256 - val_acc: 0.9300\n",
      "Epoch 60/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3770 - acc: 0.8807Epoch 00060: val_loss did not improve\n",
      "380/380 [==============================] - 0s 815us/step - loss: 0.3999 - acc: 0.8632 - val_loss: 0.2293 - val_acc: 0.9400\n",
      "Epoch 61/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4267 - acc: 0.8892Epoch 00061: val_loss did not improve\n",
      "380/380 [==============================] - 0s 827us/step - loss: 0.4232 - acc: 0.8895 - val_loss: 0.2304 - val_acc: 0.9400\n",
      "Epoch 62/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4439 - acc: 0.8494Epoch 00062: val_loss did not improve\n",
      "380/380 [==============================] - 0s 835us/step - loss: 0.4682 - acc: 0.8395 - val_loss: 0.2288 - val_acc: 0.9400\n",
      "Epoch 63/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.4067 - acc: 0.8576Epoch 00063: val_loss did not improve\n",
      "380/380 [==============================] - 0s 844us/step - loss: 0.4059 - acc: 0.8658 - val_loss: 0.2307 - val_acc: 0.9300\n",
      "Epoch 64/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4068 - acc: 0.8835Epoch 00064: val_loss improved from 0.22564 to 0.21527, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 1ms/step - loss: 0.4070 - acc: 0.8842 - val_loss: 0.2153 - val_acc: 0.9200\n",
      "Epoch 65/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.4454 - acc: 0.8646Epoch 00065: val_loss improved from 0.21527 to 0.19646, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.4231 - acc: 0.8763 - val_loss: 0.1965 - val_acc: 0.9300\n",
      "Epoch 66/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.4593 - acc: 0.8438Epoch 00066: val_loss did not improve\n",
      "380/380 [==============================] - 0s 805us/step - loss: 0.4220 - acc: 0.8553 - val_loss: 0.2039 - val_acc: 0.9200\n",
      "Epoch 67/100\n",
      "288/380 [=====================>........] - ETA: 0s - loss: 0.3754 - acc: 0.8750Epoch 00067: val_loss did not improve\n",
      "380/380 [==============================] - 0s 829us/step - loss: 0.4048 - acc: 0.8632 - val_loss: 0.2137 - val_acc: 0.9300\n",
      "Epoch 68/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.3453 - acc: 0.9000Epoch 00068: val_loss did not improve\n",
      "380/380 [==============================] - 0s 929us/step - loss: 0.3730 - acc: 0.8921 - val_loss: 0.2185 - val_acc: 0.9400\n",
      "Epoch 69/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4168 - acc: 0.8665Epoch 00069: val_loss did not improve\n",
      "380/380 [==============================] - 0s 906us/step - loss: 0.4032 - acc: 0.8711 - val_loss: 0.2182 - val_acc: 0.9400\n",
      "Epoch 70/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.4306 - acc: 0.8531Epoch 00070: val_loss did not improve\n",
      "380/380 [==============================] - 0s 859us/step - loss: 0.4195 - acc: 0.8605 - val_loss: 0.2178 - val_acc: 0.9500\n",
      "Epoch 71/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4278 - acc: 0.8778Epoch 00071: val_loss did not improve\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.4180 - acc: 0.8842 - val_loss: 0.2123 - val_acc: 0.9400\n",
      "Epoch 72/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3574 - acc: 0.9034Epoch 00072: val_loss did not improve\n",
      "380/380 [==============================] - 0s 912us/step - loss: 0.3603 - acc: 0.9000 - val_loss: 0.2116 - val_acc: 0.9500\n",
      "Epoch 73/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3815 - acc: 0.8722Epoch 00073: val_loss did not improve\n",
      "380/380 [==============================] - 0s 981us/step - loss: 0.3937 - acc: 0.8737 - val_loss: 0.1990 - val_acc: 0.9500\n",
      "Epoch 74/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4274 - acc: 0.8693Epoch 00074: val_loss improved from 0.19646 to 0.19150, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.4306 - acc: 0.8711 - val_loss: 0.1915 - val_acc: 0.9400\n",
      "Epoch 75/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.4026 - acc: 0.8812Epoch 00075: val_loss did not improve\n",
      "380/380 [==============================] - 0s 852us/step - loss: 0.4081 - acc: 0.8763 - val_loss: 0.2010 - val_acc: 0.9400\n",
      "Epoch 76/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3705 - acc: 0.8920Epoch 00076: val_loss did not improve\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.3771 - acc: 0.8842 - val_loss: 0.2137 - val_acc: 0.9400\n",
      "Epoch 77/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3661 - acc: 0.8949Epoch 00077: val_loss did not improve\n",
      "380/380 [==============================] - 0s 884us/step - loss: 0.3633 - acc: 0.8921 - val_loss: 0.2065 - val_acc: 0.9400\n",
      "Epoch 78/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3616 - acc: 0.8864Epoch 00078: val_loss did not improve\n",
      "380/380 [==============================] - 0s 858us/step - loss: 0.3568 - acc: 0.8842 - val_loss: 0.2044 - val_acc: 0.9400\n",
      "Epoch 79/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3859 - acc: 0.8551Epoch 00079: val_loss did not improve\n",
      "380/380 [==============================] - 0s 959us/step - loss: 0.3887 - acc: 0.8579 - val_loss: 0.1952 - val_acc: 0.9400\n",
      "Epoch 80/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3963 - acc: 0.8835Epoch 00080: val_loss improved from 0.19150 to 0.19102, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.3882 - acc: 0.8868 - val_loss: 0.1910 - val_acc: 0.9500\n",
      "Epoch 81/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3557 - acc: 0.9006Epoch 00081: val_loss improved from 0.19102 to 0.18641, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.3501 - acc: 0.9000 - val_loss: 0.1864 - val_acc: 0.9500\n",
      "Epoch 82/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.4036 - acc: 0.8864Epoch 00082: val_loss improved from 0.18641 to 0.18089, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.4024 - acc: 0.8842 - val_loss: 0.1809 - val_acc: 0.9400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3417 - acc: 0.8750Epoch 00083: val_loss improved from 0.18089 to 0.17540, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.3399 - acc: 0.8763 - val_loss: 0.1754 - val_acc: 0.9500\n",
      "Epoch 84/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3616 - acc: 0.8892Epoch 00084: val_loss improved from 0.17540 to 0.16989, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.3561 - acc: 0.8921 - val_loss: 0.1699 - val_acc: 0.9400\n",
      "Epoch 85/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3906 - acc: 0.8835Epoch 00085: val_loss did not improve\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.3947 - acc: 0.8789 - val_loss: 0.1763 - val_acc: 0.9400\n",
      "Epoch 86/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3331 - acc: 0.9006Epoch 00086: val_loss did not improve\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.3336 - acc: 0.8947 - val_loss: 0.1845 - val_acc: 0.9300\n",
      "Epoch 87/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3657 - acc: 0.8949Epoch 00087: val_loss did not improve\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.3721 - acc: 0.8974 - val_loss: 0.1896 - val_acc: 0.9300\n",
      "Epoch 88/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.4153 - acc: 0.8594Epoch 00088: val_loss did not improve\n",
      "380/380 [==============================] - 0s 899us/step - loss: 0.4178 - acc: 0.8605 - val_loss: 0.1912 - val_acc: 0.9300\n",
      "Epoch 89/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.2858 - acc: 0.9205Epoch 00089: val_loss did not improve\n",
      "380/380 [==============================] - 0s 981us/step - loss: 0.2773 - acc: 0.9263 - val_loss: 0.1980 - val_acc: 0.9300\n",
      "Epoch 90/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3093 - acc: 0.9091Epoch 00090: val_loss did not improve\n",
      "380/380 [==============================] - 0s 992us/step - loss: 0.3157 - acc: 0.9026 - val_loss: 0.1951 - val_acc: 0.9400\n",
      "Epoch 91/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.3332 - acc: 0.9156Epoch 00091: val_loss did not improve\n",
      "380/380 [==============================] - 0s 915us/step - loss: 0.3304 - acc: 0.9158 - val_loss: 0.1811 - val_acc: 0.9400\n",
      "Epoch 92/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3503 - acc: 0.8949Epoch 00092: val_loss did not improve\n",
      "380/380 [==============================] - 0s 904us/step - loss: 0.3468 - acc: 0.8974 - val_loss: 0.1840 - val_acc: 0.9200\n",
      "Epoch 93/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3556 - acc: 0.8977Epoch 00093: val_loss did not improve\n",
      "380/380 [==============================] - 0s 998us/step - loss: 0.3468 - acc: 0.9026 - val_loss: 0.1794 - val_acc: 0.9300\n",
      "Epoch 94/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3266 - acc: 0.8920Epoch 00094: val_loss did not improve\n",
      "380/380 [==============================] - 0s 1ms/step - loss: 0.3233 - acc: 0.8974 - val_loss: 0.1805 - val_acc: 0.9500\n",
      "Epoch 95/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.2833 - acc: 0.9261Epoch 00095: val_loss did not improve\n",
      "380/380 [==============================] - 0s 885us/step - loss: 0.2829 - acc: 0.9263 - val_loss: 0.1781 - val_acc: 0.9500\n",
      "Epoch 96/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3136 - acc: 0.8977Epoch 00096: val_loss improved from 0.16989 to 0.16816, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.3257 - acc: 0.8947 - val_loss: 0.1682 - val_acc: 0.9500\n",
      "Epoch 97/100\n",
      "320/380 [========================>.....] - ETA: 0s - loss: 0.3221 - acc: 0.8969Epoch 00097: val_loss improved from 0.16816 to 0.15945, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.3233 - acc: 0.8947 - val_loss: 0.1595 - val_acc: 0.9500\n",
      "Epoch 98/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3172 - acc: 0.8892Epoch 00098: val_loss did not improve\n",
      "380/380 [==============================] - 0s 947us/step - loss: 0.3125 - acc: 0.8921 - val_loss: 0.1654 - val_acc: 0.9300\n",
      "Epoch 99/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.3399 - acc: 0.8949Epoch 00099: val_loss did not improve\n",
      "380/380 [==============================] - 0s 982us/step - loss: 0.3319 - acc: 0.8947 - val_loss: 0.1646 - val_acc: 0.9300\n",
      "Epoch 100/100\n",
      "352/380 [==========================>...] - ETA: 0s - loss: 0.2392 - acc: 0.9261Epoch 00100: val_loss improved from 0.15945 to 0.15481, saving model to model2.detectorvgg16.weights.best.hdf5\n",
      "380/380 [==============================] - 1s 2ms/step - loss: 0.2296 - acc: 0.9289 - val_loss: 0.1548 - val_acc: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f3427ca58>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this cell\n",
    "#train the model 2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model2.detectorvgg16.weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model2.fit(bottleneck_features_train, y_train, batch_size = 32, epochs=100, validation_data=(bottleneck_features_valid, y_valid), \\\n",
    "         callbacks=[checkpointer], verbose=1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell\n",
    "#load best model and test\n",
    "model2.load_weights('model2.detectorvgg16.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 1ms/step\n",
      "Accuracy: 95.83%\n"
     ]
    }
   ],
   "source": [
    "#run this cell\n",
    "scores = model2.evaluate(bottleneck_features_test, y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 95.833333%\n"
     ]
    }
   ],
   "source": [
    "#run this cell\n",
    "#calculate accuracy another way using predict\n",
    "vgg16_predictions = [np.argmax(model2.predict(np.expand_dims(feature, axis=0))) \\\n",
    "                    for feature in bottleneck_features_test]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(vgg16_predictions)==np.argmax(y_test, axis=1)) / len(vgg16_predictions)\n",
    "\n",
    "print('\\nTest accuracy: %4f%%' % test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Machine\n",
    "### Requirements:\n",
    "1.  Show the filename, image preferable\n",
    "2.  Show the location and type of defect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"run this cell\n",
    "This confused me because I read that Keras pretrained models require preprocessing of data before inputting but \n",
    "actually it is just a reshaped np array, ie. include the num samples = 1 as the first term in the tuple.\n",
    "Actually I am not sure I am using the network correctly because the output shape is (3,3,512) and not (7,7,512)\n",
    "but the accuracy at over 95% is good enough so I have not gone back to preprocess input data.  \"\"\"\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "#from folder Inpsect, type in the file number you want to try between 131 to 150 since 1 to 130 was training data \n",
    "img = cv2.imread(\"DataSet/Inspect/133.png\")\n",
    "print(type(img), img.shape)\n",
    "img = np.reshape(img, (1, 100, 100, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 512)\n",
      "[[2.19396179e-06 1.12813887e-05 2.50640151e-05 3.65416781e-06\n",
      "  5.25513587e-06 7.53223094e-06 1.73070384e-06 3.73096532e-06\n",
      "  1.24250528e-05 1.14373397e-05 5.92392535e-05 2.93507965e-05\n",
      "  1.10563356e-04 3.65290798e-05 4.16448165e-05 9.74246814e-06\n",
      "  2.22000235e-05 1.31955137e-03 1.90481136e-04 1.25678107e-05\n",
      "  1.48349618e-05 1.12993366e-05 4.00135847e-04 2.52678710e-05\n",
      "  4.69620318e-06 4.33534888e-06 2.50902249e-05 9.73217811e-06\n",
      "  1.67405005e-06 2.45552519e-06 1.77934066e-06 7.33301840e-06\n",
      "  5.56465711e-05 4.13514827e-05 4.63261040e-06 1.77140157e-06\n",
      "  6.88898028e-04 7.01623037e-02 9.84814391e-03 4.68361031e-05\n",
      "  1.04438323e-05 3.05476040e-03 9.01450992e-01 1.16927410e-02\n",
      "  1.37845964e-05 5.19299556e-06 1.81044834e-05 2.78012449e-04\n",
      "  1.89313592e-04 1.21352705e-05]]\n",
      "<class 'numpy.ndarray'>\n",
      "Max is 0.9014509916305542\n",
      "find this one hot: (array([0]), array([42]))\n"
     ]
    }
   ],
   "source": [
    "#run through VGG16, get bottleneck feature and run through model 2\n",
    "import numpy as np\n",
    "#VGG16\n",
    "bottleneck1 = model.predict(img)\n",
    "print(bottleneck1.shape)\n",
    "#print(bottleneck1)\n",
    "#top fully connected layers of network\n",
    "result = model2.predict(bottleneck1)\n",
    "print(result)\n",
    "print(type(result))\n",
    "Maxelement = np.amax(result)\n",
    "print(\"Max is {}\".format(Maxelement))\n",
    "#this is to find the index in the one-hot encode master list of 50 classes\n",
    "index = np.where(result == np.amax(result))\n",
    "print(\"find this one hot: {}\".format(index)) #but it also alwasy prints out index 0, just ignore it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), (' D3', ' Scratch'))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"change the index number to match the 'find this one hot: (array([0]), array([z]))' in the cell above\n",
    "ie. print(labels_hot[z]).  Printout is a tuple of one-hot encoding and ('location, 'type of damage').  \n",
    "Look up the filename, ie. 131.png and the location and damage info in the CSV file\"\"\"\n",
    "print(labels_hot[42])\n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#plot the result, just type in the file number -1 (since array index starts at 0) in the images[index]\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(images[130])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
